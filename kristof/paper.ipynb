{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating https://arxiv.org/pdf/1608.02609.pdf first for $\\rho$-$\\rho$ decays\n",
    "\n",
    "## Inputs:\n",
    "- Invariant masses of intermediate resonances  \n",
    "- Acoplanarity angles\n",
    "- Variables $y_i^+$ ($y_k^-$)\n",
    "- 4 momentum of visible decay products\n",
    "- 4 momentum of intermediate resonances\n",
    "    - If cascade decays, need to provide 4-momenta of all $\\pi^+\\pi^-$ pairs which can form the resonances\n",
    "- Need to boost all four vectors where primary resonances are aligned along the z-axis.\n",
    "- Normalise all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot \n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "import os\n",
    "import random\n",
    "\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Position4\n",
    "# from lbn_modified import LBN, LBNLayer\n",
    "# from ROOT import TLorentzVector, TVector3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 1\n",
    "# 1. Set the PYTHONHASHSEED environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "# 2. Set the python built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "# 3. Set the numpy pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "# 4. Set the tensorflow pseudo-random generator at a fixed value\n",
    "tf.compat.v1.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important options\n",
    "\n",
    "# Which channel would you like to use?\n",
    "CHANNEL = 'rho_rho'\n",
    "#CHANNEL = 'rho_a1'\n",
    "#CHANNEL = 'a1_a1'\n",
    "# WARNING: IF YOU CHANGE CHANNEL, YOU HAVE TO RERUN THE WHOLE CODE FROM THE CHANNEL READ-IN!\n",
    "\n",
    "# Which kind of labels do you want to use?\n",
    "# LABELS = 'continuous'\n",
    "#LABELS = 'binary1'\n",
    "LABELS = 'binary2'\n",
    "#WARNING: IF YOU CHANGE LABELS, YOU HAVE TO RERUN THE CREATE LABELS PART!\n",
    "\n",
    "# Which kind of AUC would you like to use?\n",
    "#AUC = 'unweighted'\n",
    "AUC = 'weighted'\n",
    "#WHEN YOU CHANGE AUC, YOU DON'T HAVE TO RERUN ANYTHING!\n",
    "\n",
    "# The output filenames\n",
    "FILENAME_OPTIONS = CHANNEL + '_' + LABELS + '_' + AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_tt = uproot.open(\"../MVAFILE_AllHiggs_tt_new.root\")[\"ntuple\"]\n",
    "\n",
    "variables = [\n",
    "            \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\",\n",
    "            \"aco_angle_1\",\n",
    "            \"aco_angle_5\", \"aco_angle_6\", \"aco_angle_7\",\n",
    "            \"mva_dm_1\",\"mva_dm_2\",\n",
    "            \"tau_decay_mode_1\",\"tau_decay_mode_2\",\n",
    "            \"ip_x_1\", \"ip_y_1\", \"ip_z_1\", \"ip_x_2\", \"ip_y_2\", \"ip_z_2\", # need impact parameter for aco_angle_6\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", # charged pion 1\n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", # charged pion 2\n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\", # neutral pion 1\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", # neutral pion 2\n",
    "            \"y_1_1\", \"y_1_2\" # y variables\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line takes a long time!\n",
    "df = tree_tt.pandas.df(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHANNEL == 'rho_rho':\n",
    "    # select only rho-rho events\n",
    "    df_filtered = df[(df['mva_dm_1']==1) & (df['mva_dm_2']==1) & (df[\"tau_decay_mode_1\"] == 1) & (df[\"tau_decay_mode_2\"] == 1)]\n",
    "\n",
    "elif CHANNEL == 'rho_a1':\n",
    "    # select only rho-a1 events\n",
    "    df_filtered = df[(df['mva_dm_1']==1) & (df['mva_dm_2']==10) & (df[\"tau_decay_mode_1\"] == 1)]\n",
    "\n",
    "elif CHANNEL == 'a1_a1':\n",
    "    # select only a1-a1 events\n",
    "    df_filtered = df[(df['mva_dm_1']==10) & (df['mva_dm_2']==10)]\n",
    "    \n",
    "else:\n",
    "    print('CHANNEL not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels y\n",
    "\n",
    "# necessary for binary2 only:\n",
    "df_filtered_ps = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2)]\n",
    "df_filtered_sm = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_sm\"]/2)]\n",
    "\n",
    "if LABELS == 'continuous':\n",
    "    # non-binary\n",
    "    y = df_filtered[\"wt_cp_sm\"] / (df_filtered[\"wt_cp_ps\"] + df_filtered[\"wt_cp_sm\"])\n",
    "\n",
    "elif LABELS == 'binary1':\n",
    "    # binary method 1\n",
    "    y = (~(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2).to_numpy()).astype(int)\n",
    "\n",
    "elif LABELS == 'binary2':\n",
    "    # binary method 2\n",
    "    y_sm = pd.DataFrame(np.ones(df_filtered_sm.shape[0]))\n",
    "    y_ps = pd.DataFrame(np.zeros(df_filtered_ps.shape[0]))\n",
    "    y = pd.concat([y_sm, y_ps]).to_numpy()\n",
    "\n",
    "else:\n",
    "    print('LABELS not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = df_filtered[\"wt_cp_sm\"].to_numpy()\n",
    "w_b = df_filtered[\"wt_cp_ps\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The particle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse particle information\n",
    "#columns = ['E', 'px', 'py', 'pz']\n",
    "\n",
    "pi_1 = df_filtered[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_2 = df_filtered[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "pi0_1 = df_filtered[['pi0_E_1', \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\"]].to_numpy()\n",
    "pi0_2 = df_filtered[['pi0_E_2', \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct resonance 4 momentum\n",
    "rho_1 = pi_1 + pi0_1\n",
    "rho_2 = pi_2 + pi0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate invariant masses\n",
    "rho_1_m2 = rho_1[:, 0]**2 - rho_1[:, 1]**2 - rho_1[:, 2]**2 - rho_1[:, 3]**2\n",
    "rho_2_m2 = rho_2[:, 0]**2 - rho_2[:, 1]**2 - rho_2[:, 2]**2 - rho_2[:, 3]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = Momentum4(pi_1[:, 0], pi_1[:, 1], pi_1[:, 2], pi_1[:, 3]) # p3 = charged pion 1\n",
    "p4 = Momentum4(pi_2[:, 0], pi_2[:, 1], pi_2[:, 2], pi_2[:, 3]) # p4 = charged pion 2\n",
    "p1 = Momentum4(pi0_1[:, 0], pi0_1[:, 1], pi0_1[:, 2], pi0_1[:, 3]) # p1 = neutral pion 1\n",
    "p2 = Momentum4(pi0_2[:, 0], pi0_2[:, 1], pi0_2[:, 2], pi0_2[:, 3]) # p2 = neutral pion 2\n",
    "rest_frame = p1 + p2 + p3 + p4\n",
    "boost = Momentum4(rest_frame[0], -rest_frame[1], -rest_frame[2], -rest_frame[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_boosted = p1.boost_particle(boost)\n",
    "p3_boosted = p3.boost_particle(boost)\n",
    "p2_boosted = p2.boost_particle(boost)\n",
    "p4_boosted = p4.boost_particle(boost)\n",
    "\n",
    "r1_boosted = p1_boosted + p3_boosted\n",
    "r2_boosted = p2_boosted + p4_boosted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of other aco_angles\n",
    "\n",
    "<font size=4 color='red'>__You can skip this part__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_1 = df_filtered['y_1_1'].to_numpy()\n",
    "y_1_2 = df_filtered['y_1_2'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aco(p1_boosted2, p2_boosted2, p3_boosted2, p4_boosted2, y_1=[], y_2=[]):\n",
    "    \"\"\"\n",
    "    The input 4-vectors should be:\n",
    "    Momentum4 instances with shape 4 by ?\n",
    "    The energy (first) row doesn't matter, can be anything\n",
    "    \"\"\"\n",
    "    \n",
    "    if y_1 == [] or y_2 == []: # if no given y-s, then use the globally defined ones\n",
    "        y_1 = y_1_1\n",
    "        y_2 = y_1_2\n",
    "        print('using default y-s')\n",
    "    \n",
    "    i = 0\n",
    "    phi_cps = []\n",
    "    def unit(vect):\n",
    "        return vect / np.linalg.norm(vect)\n",
    "    for pp1, pp2, pp3, pp4 in zip(p1_boosted2[:].T, p2_boosted2[:].T, p3_boosted2[:].T, p4_boosted2[:].T):\n",
    "        n1 = pp1[1:] - np.dot(pp1[1:], unit(pp3[1:])) * unit(pp3[1:])\n",
    "        n2 = pp2[1:] - np.dot(pp2[1:], unit(pp4[1:])) * unit(pp4[1:])\n",
    "        n1 = unit(n1)\n",
    "        n2 = unit(n2)\n",
    "\n",
    "        angle = np.arccos(np.dot(n1, n2))\n",
    "        sign = np.dot(unit(pp4[1:]), np.cross(n1, n2))\n",
    "\n",
    "        # shift 1\n",
    "        if sign < 0:\n",
    "            angle = 2 * np.pi - angle\n",
    "        \n",
    "        # this part should be commented out\n",
    "        if y_1[i] * y_2[i] < 0:\n",
    "            if angle < np.pi:\n",
    "                angle += np.pi\n",
    "            else:\n",
    "                angle -= np.pi\n",
    "                \n",
    "        phi_cps.append(angle)\n",
    "        if i%100000==0:\n",
    "            print('finished instance', i)\n",
    "        i += 1\n",
    "                \n",
    "    return phi_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_1 = df_filtered[[\"ip_x_1\", \"ip_y_1\", \"ip_z_1\"]].to_numpy()\n",
    "ip_2 = df_filtered[[\"ip_x_2\", \"ip_y_2\", \"ip_z_2\"]].to_numpy()\n",
    "zeros = np.reshape(np.zeros(len(ip_1)), (-1, 1))\n",
    "ip_1 = np.concatenate([zeros, ip_1], axis=1)\n",
    "ip_2 = np.concatenate([zeros, ip_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate aco_angle_1\n",
    "#phi_cps = calc_aco(p1_boosted, p2_boosted, p3_boosted, p4_boosted)\n",
    "\n",
    "# calculate aco_angle_6\n",
    "aco_6_calculated = calc_aco(ip_1.T, ip_2.T, p3_boosted, p4_boosted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare calculated aco_angle_6-s\n",
    "\n",
    "<font size=4 color='red'>__You can skip this part__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS UNBOOSTED, SO GIVES WRONG RESULTS\n",
    "\n",
    "aco_angle_6_ps = df_filtered_ps['aco_angle_6'].to_numpy()\n",
    "aco_angle_6_sm = df_filtered_sm['aco_angle_6'].to_numpy()\n",
    "\n",
    "pi_1_ps = df_filtered_ps[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_1_sm = df_filtered_sm[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_2_ps = df_filtered_ps[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "pi_2_sm = df_filtered_sm[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "ip_1_ps = df_filtered_ps[[\"ip_x_1\", \"ip_y_1\", \"ip_z_1\"]].to_numpy()\n",
    "ip_1_sm = df_filtered_sm[[\"ip_x_1\", \"ip_y_1\", \"ip_z_1\"]].to_numpy()\n",
    "ip_2_ps = df_filtered_ps[[\"ip_x_2\", \"ip_y_2\", \"ip_z_2\"]].to_numpy()\n",
    "ip_2_sm = df_filtered_sm[[\"ip_x_2\", \"ip_y_2\", \"ip_z_2\"]].to_numpy()\n",
    "zeros_ps = np.reshape(np.zeros(len(ip_1_ps)), (-1, 1))\n",
    "zeros_sm = np.reshape(np.zeros(len(ip_1_sm)), (-1, 1))\n",
    "ip_1_ps = np.concatenate([zeros_ps, ip_1_ps], axis=1)\n",
    "ip_1_sm = np.concatenate([zeros_sm, ip_1_sm], axis=1)\n",
    "ip_2_ps = np.concatenate([zeros_ps, ip_2_ps], axis=1)\n",
    "ip_2_sm = np.concatenate([zeros_sm, ip_2_sm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BOOSTED ACCORDING TO ALIE'S METHOD, GIVES ALMOST GOOD RESULTS\n",
    "\n",
    "aco_angle_6_ps = df_filtered_ps['aco_angle_6'].to_numpy()\n",
    "aco_angle_6_sm = df_filtered_sm['aco_angle_6'].to_numpy()\n",
    "\n",
    "pi_1_ps = Momentum4(df_filtered_ps[\"pi_E_1\"],df_filtered_ps[\"pi_px_1\"],df_filtered_ps[\"pi_py_1\"],df_filtered_ps[\"pi_pz_1\"])\n",
    "pi_1_sm = Momentum4(df_filtered_sm[\"pi_E_1\"],df_filtered_sm[\"pi_px_1\"],df_filtered_sm[\"pi_py_1\"],df_filtered_sm[\"pi_pz_1\"])\n",
    "pi_2_ps = Momentum4(df_filtered_ps[\"pi_E_2\"],df_filtered_ps[\"pi_px_2\"],df_filtered_ps[\"pi_py_2\"],df_filtered_ps[\"pi_pz_2\"])\n",
    "pi_2_sm = Momentum4(df_filtered_sm[\"pi_E_2\"],df_filtered_sm[\"pi_px_2\"],df_filtered_sm[\"pi_py_2\"],df_filtered_sm[\"pi_pz_2\"])\n",
    "ip_1_ps = Momentum4(np.zeros(len(df_filtered_ps[\"ip_x_1\"])),df_filtered_ps[\"ip_x_1\"],df_filtered_ps[\"ip_y_1\"],df_filtered_ps[\"ip_z_1\"])\n",
    "ip_1_sm = Momentum4(np.zeros(len(df_filtered_sm[\"ip_x_1\"])),df_filtered_sm[\"ip_x_1\"],df_filtered_sm[\"ip_y_1\"],df_filtered_sm[\"ip_z_1\"])\n",
    "ip_2_ps = Momentum4(np.zeros(len(df_filtered_ps[\"ip_x_2\"])),df_filtered_ps[\"ip_x_2\"],df_filtered_ps[\"ip_y_2\"],df_filtered_ps[\"ip_z_2\"])\n",
    "ip_2_sm = Momentum4(np.zeros(len(df_filtered_sm[\"ip_x_2\"])),df_filtered_sm[\"ip_x_2\"],df_filtered_sm[\"ip_y_2\"],df_filtered_sm[\"ip_z_2\"])\n",
    "\n",
    "com_ps = Momentum4(pi_1_ps+pi_2_ps)\n",
    "com_sm = Momentum4(pi_1_sm+pi_2_sm)\n",
    "boost_ps = Momentum4(com_ps[0], -com_ps[1], -com_ps[2], -com_ps[3])\n",
    "boost_sm = Momentum4(com_sm[0], -com_sm[1], -com_sm[2], -com_sm[3])\n",
    "boost_ps = -com_ps\n",
    "boost_sm = -com_sm\n",
    "pi_1_ps = pi_1_ps.boost_particle(boost_ps)[:].T\n",
    "pi_1_sm = pi_1_sm.boost_particle(boost_sm)[:].T\n",
    "pi_2_ps = pi_2_ps.boost_particle(boost_ps)[:].T\n",
    "pi_2_sm = pi_2_sm.boost_particle(boost_sm)[:].T\n",
    "ip_1_ps = ip_1_ps.boost_particle(boost_ps)[:].T\n",
    "ip_1_sm = ip_1_sm.boost_particle(boost_sm)[:].T\n",
    "ip_2_ps = ip_2_ps.boost_particle(boost_ps)[:].T\n",
    "ip_2_sm = ip_2_sm.boost_particle(boost_sm)[:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_1_ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate aco_angle_6\n",
    "aco_6_calculated_ps = calc_aco(ip_1_ps.T, ip_2_ps.T, pi_1_ps.T, pi_2_ps.T)\n",
    "aco_6_calculated_sm = calc_aco(ip_1_sm.T, ip_2_sm.T, pi_1_sm.T, pi_2_sm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to plot 'signal' vs 'background' for a specified variables\n",
    "# useful to check whether a variable gives some separation between\n",
    "# signal and background states\n",
    "def plot_signal_background(data1, data2, column,\n",
    "                        bins=100, x_uplim=0, **kwargs):\n",
    "\n",
    "    if \"alpha\" not in kwargs:\n",
    "        kwargs[\"alpha\"] = 0.5\n",
    "\n",
    "    df1 = data1[column]\n",
    "    df2 = data2[column]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    #df1 = df1.sample(3000, random_state=1234)\n",
    "    #df2 = df2.sample(3000, random_state=1234)\n",
    "    #low = max(min(df1.min(), df2.min()),-5)\n",
    "    low = 0\n",
    "    #print(df1.min())\n",
    "    #print(df2.min())\n",
    "    high = max(df1.max(), df2.max())\n",
    "    if x_uplim != 0: high = x_uplim\n",
    "\n",
    "    ax.hist(df1, bins=bins, range=(low,high), **kwargs)\n",
    "    ax.hist(df2, bins=bins, range=(low,high), **kwargs)\n",
    "    if column == \"aco_angle_6\":\n",
    "        plt.title('given aco_angle_6 (true values)')\n",
    "    else:\n",
    "        plt.title(column)\n",
    "    \n",
    "    if x_uplim != 0:\n",
    "        ax.set_xlim(0,x_uplim)\n",
    "\n",
    "    # ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot my calculated aco_angle_6 values\n",
    "aco_6_calculated_ps_df = pd.DataFrame(aco_6_calculated_ps, columns=['aco_angle_6 calculated from low-level data'])\n",
    "aco_6_calculated_sm_df = pd.DataFrame(aco_6_calculated_sm, columns=['aco_angle_6 calculated from low-level data'])\n",
    "plot_signal_background(aco_6_calculated_ps_df, aco_6_calculated_sm_df, 'aco_angle_6 calculated from low-level data', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the given aco_angle_6 values\n",
    "aco_angle_6_ps_df = pd.DataFrame(aco_angle_6_ps, columns=['aco_angle_6'])\n",
    "aco_angle_6_sm_df = pd.DataFrame(aco_angle_6_sm, columns=['aco_angle_6'])\n",
    "plot_signal_background(aco_angle_6_ps_df, aco_angle_6_sm_df, 'aco_angle_6', bins=50)\n",
    "\n",
    "# THIS ONLY WORKS FOR THE RHO-RHO CHANNEL I GUESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aco_6_calculated_merged = aco_6_calculated_ps_df.append(aco_6_calculated_sm_df, ignore_index=True)\n",
    "#aco_angle_6_merged = aco_angle_6_ps_df.append(aco_angle_6_sm_df, ignore_index=True)\n",
    "#plt.hist(aco_6_calculated_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aco_6_calculated_merged = pd.concat([aco_6_calculated_ps_df, aco_6_calculated_sm_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aco_angle_6_merged = pd.concat([aco_angle_6_sm_df, aco_angle_6_ps_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(aco_6_calculated_merged.to_numpy(), bins=100, range=(0, 2*np.pi))\n",
    "plt.title('calculated aco_angle_6 for the full dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(aco_angle_6_merged.to_numpy(), bins=100, range=(0, 2*np.pi))\n",
    "plt.title('given aco_angle_6 for the full dataset (true values)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check calculations on aco_angle_1\n",
    "\n",
    "<font size=4 color='red'>__You can skip this part__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aco_angle_1_ps = df_filtered_ps['aco_angle_1'].to_numpy()\n",
    "aco_angle_1_sm = df_filtered_sm['aco_angle_1'].to_numpy()\n",
    "y_1_ps = df_filtered_ps['y_1_1'].to_numpy()\n",
    "y_1_sm = df_filtered_sm['y_1_2'].to_numpy()\n",
    "y_2_ps = df_filtered_ps['y_1_1'].to_numpy()\n",
    "y_2_sm = df_filtered_sm['y_1_2'].to_numpy()\n",
    "\n",
    "pi_1_ps = Momentum4(df_filtered_ps[\"pi_E_1\"],df_filtered_ps[\"pi_px_1\"],df_filtered_ps[\"pi_py_1\"],df_filtered_ps[\"pi_pz_1\"])\n",
    "pi_1_sm = Momentum4(df_filtered_sm[\"pi_E_1\"],df_filtered_sm[\"pi_px_1\"],df_filtered_sm[\"pi_py_1\"],df_filtered_sm[\"pi_pz_1\"])\n",
    "pi_2_ps = Momentum4(df_filtered_ps[\"pi_E_2\"],df_filtered_ps[\"pi_px_2\"],df_filtered_ps[\"pi_py_2\"],df_filtered_ps[\"pi_pz_2\"])\n",
    "pi_2_sm = Momentum4(df_filtered_sm[\"pi_E_2\"],df_filtered_sm[\"pi_px_2\"],df_filtered_sm[\"pi_py_2\"],df_filtered_sm[\"pi_pz_2\"])\n",
    "pi0_1_ps = Momentum4(df_filtered_ps[\"pi0_E_1\"],df_filtered_ps[\"pi0_px_1\"],df_filtered_ps[\"pi0_py_1\"],df_filtered_ps[\"pi0_pz_1\"])\n",
    "pi0_1_sm = Momentum4(df_filtered_sm[\"pi0_E_1\"],df_filtered_sm[\"pi0_px_1\"],df_filtered_sm[\"pi0_py_1\"],df_filtered_sm[\"pi0_pz_1\"])\n",
    "pi0_2_ps = Momentum4(df_filtered_ps[\"pi0_E_2\"],df_filtered_ps[\"pi0_px_2\"],df_filtered_ps[\"pi0_py_2\"],df_filtered_ps[\"pi0_pz_2\"])\n",
    "pi0_2_sm = Momentum4(df_filtered_sm[\"pi0_E_2\"],df_filtered_sm[\"pi0_px_2\"],df_filtered_sm[\"pi0_py_2\"],df_filtered_sm[\"pi0_pz_2\"])\n",
    "\n",
    "com_ps = Momentum4(pi_1_ps+pi_2_ps)\n",
    "com_sm = Momentum4(pi_1_sm+pi_2_sm)\n",
    "boost_ps = Momentum4(com_ps[0], -com_ps[1], -com_ps[2], -com_ps[3])\n",
    "boost_sm = Momentum4(com_sm[0], -com_sm[1], -com_sm[2], -com_sm[3])\n",
    "boost_ps = -com_ps\n",
    "boost_sm = -com_sm\n",
    "pi_1_ps = pi_1_ps.boost_particle(boost_ps)[:].T\n",
    "pi_1_sm = pi_1_sm.boost_particle(boost_sm)[:].T\n",
    "pi_2_ps = pi_2_ps.boost_particle(boost_ps)[:].T\n",
    "pi_2_sm = pi_2_sm.boost_particle(boost_sm)[:].T\n",
    "pi0_1_ps = pi0_1_ps.boost_particle(boost_ps)[:].T\n",
    "pi0_1_sm = pi0_1_sm.boost_particle(boost_sm)[:].T\n",
    "pi0_2_ps = pi0_2_ps.boost_particle(boost_ps)[:].T\n",
    "pi0_2_sm = pi0_2_sm.boost_particle(boost_sm)[:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate aco_angle_6\n",
    "aco_1_calculated_ps = calc_aco(pi0_1_ps.T, pi0_2_ps.T, pi_1_ps.T, pi_2_ps.T, y_1_ps, y_2_ps)\n",
    "aco_1_calculated_sm = calc_aco(pi0_1_sm.T, pi0_2_sm.T, pi_1_sm.T, pi_2_sm.T, y_1_sm, y_2_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot my calculated aco_angle_6 values\n",
    "aco_1_calculated_ps_df = pd.DataFrame(aco_1_calculated_ps, columns=['aco_angle_1 calculated from low-level data'])\n",
    "aco_1_calculated_sm_df = pd.DataFrame(aco_1_calculated_sm, columns=['aco_angle_1 calculated from low-level data'])\n",
    "plot_signal_background(aco_1_calculated_ps_df, aco_1_calculated_sm_df, 'aco_angle_1 calculated from low-level data', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the given aco_angle_6 values\n",
    "aco_angle_1_ps_df = pd.DataFrame(aco_angle_1_ps, columns=['aco_angle_1'])\n",
    "aco_angle_1_sm_df = pd.DataFrame(aco_angle_1_sm, columns=['aco_angle_1'])\n",
    "plot_signal_background(aco_angle_1_ps_df, aco_angle_1_sm_df, 'aco_angle_1', bins=50)\n",
    "\n",
    "# THIS ONLY WORKS FOR THE RHO-RHO CHANNEL I GUESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying some calculation of other aco_angles\n",
    "\n",
    "<font size=4 color='red'>__You can skip this part__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aco_5_calculated_ps = calc_aco(pi_1_ps.T, pi_2_ps.T, ip_1_ps.T, ip_2_ps.T, y_1_ps, y_2_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(aco_5_calculated_ps), bins=100, range=(0, 2*np.pi))\n",
    "plt.title('calculated aco_angle_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aco_5_calculated_sm = calc_aco(pi0_1_sm.T, ip_1_sm.T, pi_1_sm.T, pi_2_sm.T, y_1_sm, y_2_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(aco_5_calculated_sm), bins=100, range=(0, 2*np.pi))\n",
    "plt.title('calculated aco_angle_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit vectors along the momenta of the primary resonances\n",
    "unit1 = (r1_boosted[1:, :] / np.linalg.norm(r1_boosted[1:, :], axis=0)).transpose()\n",
    "unit2 = (r2_boosted[1:, :] / np.linalg.norm(r2_boosted[1:, :], axis=0)).transpose()\n",
    "\n",
    "# probably there's a faster way of doing this\n",
    "zaxis = np.array([np.array([0., 0., 1.]) for _ in range(len(unit1))])\n",
    "\n",
    "axes1 = np.cross(unit1, zaxis)\n",
    "axes2 = np.cross(unit2, zaxis)\n",
    "\n",
    "dotproduct1 = (unit1*zaxis).sum(1)\n",
    "angles1 = np.arccos(dotproduct1)\n",
    "dotproduct2 = (unit2*zaxis).sum(1)\n",
    "angles2 = np.arccos(dotproduct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rotated test_vector is:\n",
      "[ 0.  0. -1.]\n"
     ]
    }
   ],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / np.dot(axis, axis)**0.5\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def rotate(vect, axis, theta):\n",
    "    return np.dot(rotation_matrix(axis, theta), vect)\n",
    "\n",
    "test_vector = [1, 0, 0]\n",
    "test_axis = [0, 1, 0]\n",
    "test_angle = np.pi/2\n",
    "\n",
    "print('The rotated test_vector is:')\n",
    "print(rotate(test_vector, test_axis, test_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished rotating 3-vector 0\n",
      "finished rotating 3-vector 100000\n",
      "finished rotating 3-vector 200000\n",
      "finished rotating 3-vector 300000\n",
      "finished rotating 3-vector 400000\n",
      "finished rotating 3-vector 500000\n",
      "finished rotating 3-vector 600000\n",
      "finished rotating 3-vector 700000\n",
      "finished rotating 3-vector 800000\n",
      "finished rotating 3-vector 900000\n"
     ]
    }
   ],
   "source": [
    "# it would be nice to be able to do the rotation in a vectorized form, like this:\n",
    "#p1rot = rotate(p1_boosted[1:, :].transpose(), axes1, angles1)\n",
    "\n",
    "p1rot = []\n",
    "p2rot = []\n",
    "p3rot = []\n",
    "p4rot = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1rot.append(rotate(p1_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p2rot.append(rotate(p2_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p3rot.append(rotate(p3_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p4rot.append(rotate(p4_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    if i%100000==0:\n",
    "        print('finished rotating 3-vector', i)\n",
    "p1rot = np.array(p1rot)\n",
    "p2rot = np.array(p2rot)\n",
    "p3rot = np.array(p3rot)\n",
    "p4rot = np.array(p4rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished getting rotated 4-vector 0\n",
      "finished getting rotated 4-vector 100000\n",
      "finished getting rotated 4-vector 200000\n",
      "finished getting rotated 4-vector 300000\n",
      "finished getting rotated 4-vector 400000\n",
      "finished getting rotated 4-vector 500000\n",
      "finished getting rotated 4-vector 600000\n",
      "finished getting rotated 4-vector 700000\n",
      "finished getting rotated 4-vector 800000\n",
      "finished getting rotated 4-vector 900000\n"
     ]
    }
   ],
   "source": [
    "# this should be vectorized as well\n",
    "p1_rotated = []\n",
    "p2_rotated = []\n",
    "p3_rotated = []\n",
    "p4_rotated = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1_rotated.append([p1_boosted[0, i], p1rot[i, 0], p1rot[i, 1], p1rot[i, 2]])\n",
    "    p2_rotated.append([p2_boosted[0, i], p2rot[i, 0], p2rot[i, 1], p2rot[i, 2]])\n",
    "    p3_rotated.append([p3_boosted[0, i], p3rot[i, 0], p3rot[i, 1], p3rot[i, 2]])\n",
    "    p4_rotated.append([p4_boosted[0, i], p4rot[i, 0], p4rot[i, 1], p4rot[i, 2]])\n",
    "    if i%100000==0:\n",
    "        print('finished getting rotated 4-vector', i)\n",
    "p1_rotated = np.array(p1_rotated).transpose()\n",
    "p2_rotated = np.array(p2_rotated).transpose()\n",
    "p3_rotated = np.array(p3_rotated).transpose()\n",
    "p4_rotated = np.array(p4_rotated).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and labels\n",
    "\n",
    "aco_angle_1 = df_filtered['aco_angle_1'].to_numpy()\n",
    "y_1_1 = df_filtered['y_1_1'].to_numpy()\n",
    "y_1_2 = df_filtered['y_1_2'].to_numpy()\n",
    "\n",
    "aco_angle_5 = df_filtered['aco_angle_5'].to_numpy()\n",
    "aco_angle_6 = df_filtered['aco_angle_6'].to_numpy()\n",
    "aco_angle_7 = df_filtered['aco_angle_7'].to_numpy()\n",
    "\n",
    "# this will use the unrotated, boosted 4-vectors:\n",
    "E1 = p1_boosted[0]\n",
    "px1 = p1_boosted[1]\n",
    "py1 = p1_boosted[2]\n",
    "pz1 = p1_boosted[3]\n",
    "E2 = p2_boosted[0]\n",
    "px2 = p2_boosted[1]\n",
    "py2 = p2_boosted[2]\n",
    "pz2 = p2_boosted[3]\n",
    "E3 = p3_boosted[0]\n",
    "px3 = p3_boosted[1]\n",
    "py3 = p3_boosted[2]\n",
    "pz3 = p3_boosted[3]\n",
    "E4 = p4_boosted[0]\n",
    "px4 = p4_boosted[1]\n",
    "py4 = p4_boosted[2]\n",
    "pz4 = p4_boosted[3]\n",
    "\n",
    "# this will use the rotated, boosted 4-vectors:\n",
    "E1r = p1_rotated[0]\n",
    "px1r = p1_rotated[1]\n",
    "py1r = p1_rotated[2]\n",
    "pz1r = p1_rotated[3]\n",
    "E2r = p2_rotated[0]\n",
    "px2r = p2_rotated[1]\n",
    "py2r = p2_rotated[2]\n",
    "pz2r = p2_rotated[3]\n",
    "E3r = p3_rotated[0]\n",
    "px3r = p3_rotated[1]\n",
    "py3r = p3_rotated[2]\n",
    "pz3r = p3_rotated[3]\n",
    "E4r = p4_rotated[0]\n",
    "px4r = p4_rotated[1]\n",
    "py4r = p4_rotated[2]\n",
    "pz4r = p4_rotated[3]\n",
    "\n",
    "# y is defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_aco_angles_added = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stanley checking the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.c_[E4r, px4r, py4r, pz4r]\n",
    "b=np.load('../stanley/potential_2016/pi_2_transformed.npy', allow_pickle=True)\n",
    "np.testing.assert_array_almost_equal(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, w_a, w_b, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    w_a = w_a[~nan_mask_y]\n",
    "    w_b = w_b[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y, w_a, w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple NN\n",
    "def baseline_model2(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(38, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model\n",
    "\n",
    "def baseline_model(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(300, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define a function to plot the ROC curves - just makes the roc_curve look nicer than the default\n",
    "def plot_roc_curve(fpr, tpr, auc, filename='roc_untitled'):\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.grid()\n",
    "    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n",
    "            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n",
    "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "    ax.plot(lims, lims, 'k--')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.savefig('paper/' + filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(i):\n",
    "    if i==1:\n",
    "        X = np.reshape(aco_angle_1, (-1, 1))\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==2:\n",
    "        X = np.stack([aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==3:\n",
    "        X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==4:\n",
    "        X = np.stack([aco_angle_1, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==5:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "    if i==6:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "\n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if i==1:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7], axis=1)\n",
    "        if i==2:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==3:\n",
    "            X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==4:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==5:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==6:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        \n",
    "        \n",
    "    return X\n",
    "\n",
    "def run_config(config_num, y, w_a, w_b, epoch_number, batch_number):\n",
    "    X = load_config(config_num)\n",
    "\n",
    "    want_filter_nans = False\n",
    "    if CHANNEL == 'rho_a1' or CHANNEL == 'a1_a1':\n",
    "        want_filter_nans = True\n",
    "    if want_filter_nans:\n",
    "        X, y, w_a, w_b = filter_nans(X, y, w_a, w_b, config_num)\n",
    "        \n",
    "    w_a_train, w_a_test, w_b_train, w_b_test  = train_test_split(w_a, w_b, test_size=0.2, random_state=123456)\n",
    "    \n",
    "    # split X and y into train and validation dataset \n",
    "\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=123456,\n",
    "        #stratify=y.values,\n",
    "    )\n",
    "    \n",
    "    # define early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # first run the training for simple case with just 1 variable\n",
    "    history = tf.keras.callbacks.History()\n",
    "\n",
    "    model = baseline_model(X.shape[1])\n",
    "\n",
    "    model.fit(\n",
    "                    X_train, y_train,\n",
    "                    batch_size=batch_number,\n",
    "                    epochs=epoch_number,\n",
    "                    callbacks=[history,early_stop],\n",
    "                    validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Extract number of run epochs from the training history\n",
    "    epochs = range(1, len(history.history[\"loss\"])+1)\n",
    "\n",
    "    # Extract loss on training and validation ddataset and plot them together\n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs, history.history[\"loss\"], \"o-\", label=\"Training\")\n",
    "    plt.plot(epochs, history.history[\"val_loss\"], \"o-\", label=\"Test\")\n",
    "    plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "#     plt.savefig('paper/history_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    plt.close()\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    # plot ROC curve for improved training\n",
    "    y_proba = model.predict_proba(X_test) # outputs two probabilties\n",
    "    \n",
    "    def stanley_auc():\n",
    "        #Stanley's way of calculating auc\n",
    "        y_pred_roc = model.predict(X_test) #for test dataset\n",
    "        #y_pred_roc = model.predict(X) # for full dataset\n",
    "        y_pred_roc_final = np.r_[y_pred_roc, y_pred_roc]\n",
    "        set_a = np.ones(len(y_pred_roc))\n",
    "        set_b = np.zeros(len(y_pred_roc))\n",
    "        y_label_roc = np.r_[set_a, set_b]\n",
    "        w_roc = np.r_[w_a_test, w_b_test] # for test dataset\n",
    "        #w_roc = np.r_[w_a, w_b] # for full dataset\n",
    "        #print('========================================')\n",
    "        #print(y_label_roc.shape)\n",
    "        #print(y_pred_roc_final.shape)\n",
    "        #print(w_roc.shape)\n",
    "        #print('========================================')\n",
    "        auc = roc_auc_score(y_label_roc, y_pred_roc_final, sample_weight=w_roc)\n",
    "        return auc\n",
    "    \n",
    "    if LABELS == 'continuous':\n",
    "        # the original way of calculating auc\n",
    "        y_binary = (y_test > 0.5) * 1.0\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_binary, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_binary, y_proba)\n",
    "        \n",
    "    if LABELS == 'binary1' or LABELS == 'binary2':\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        \n",
    "#     plot_roc_curve(fpr, tpr, auc, 'roc_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    print(auc)\n",
    "    f = open(FILENAME_OPTIONS + '.txt', 'a')\n",
    "    f.write(str(config_num) + ',' + str(auc) + '\\n')\n",
    "    f.close()\n",
    "    return model, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(exp_no, epoch_no=50, batch_no=1000):\n",
    "#     confs = [1, 2, 3, 4, 5, 6]\n",
    "    confs = [3]\n",
    "    for i in range(exp_no):\n",
    "        for conf in confs:\n",
    "            model, X = run_config(conf, y, w_a.copy(), w_b.copy(), epoch_no, batch_no)\n",
    "            print('CONFIG', conf, 'DONE')\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print('##########################################################')\n",
    "        print('DONE ITERATION', i)\n",
    "        print('##########################################################')\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "    return model, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [998268, 987883]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-05cad3c8e87b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#run_experiments(8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-97b3a35b5a18>\u001b[0m in \u001b[0;36mrun_experiments\u001b[1;34m(exp_no, epoch_no, batch_no)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CONFIG'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DONE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-855a290eff13>\u001b[0m in \u001b[0;36mrun_config\u001b[1;34m(config_num, y, w_a, w_b, epoch_number, batch_number)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m#print(y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     X_train, X_test, y_train, y_test  = train_test_split(\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\msci\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2125\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2127\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\msci\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\msci\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [998268, 987883]"
     ]
    }
   ],
   "source": [
    "# run 8 experiments\n",
    "#run_experiments(8)\n",
    "\n",
    "model = run_experiments(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s = np.load('../stanley/testing/X.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_almost_equal(X,X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
