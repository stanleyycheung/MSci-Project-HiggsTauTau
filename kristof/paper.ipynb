{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating https://arxiv.org/pdf/1608.02609.pdf first for $\\rho$-$\\rho$ decays\n",
    "\n",
    "## Inputs:\n",
    "- Invariant masses of intermediate resonances  \n",
    "- Acoplanarity angles\n",
    "- Variables $y_i^+$ ($y_k^-$)\n",
    "- 4 momentum of visible decay products\n",
    "- 4 momentum of intermediate resonances\n",
    "    - If cascade decays, need to provide 4-momenta of all $\\pi^+\\pi^-$ pairs which can form the resonances\n",
    "- Need to boost all four vectors where primary resonances are aligned along the z-axis.\n",
    "- Normalise all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n"
     ]
    }
   ],
   "source": [
    "import uproot \n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Position4\n",
    "from lbn_modified import LBN, LBNLayer\n",
    "from ROOT import TLorentzVector, TVector3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important options\n",
    "\n",
    "# Which channel would you like to use?\n",
    "CHANNEL = 'rho_rho'\n",
    "#CHANNEL = 'rho_a1'\n",
    "#CHANNEL = 'a1_a1'\n",
    "# WARNING: IF YOU CHANGE CHANNEL, YOU HAVE TO RERUN THE WHOLE CODE FROM THE CHANNEL READ-IN!\n",
    "\n",
    "# Which kind of labels do you want to use?\n",
    "#LABELS = 'continuous'\n",
    "LABELS = 'binary1'\n",
    "#LABELS = 'binary2'\n",
    "#WARNING: IF YOU CHANGE LABELS, YOU HAVE TO RERUN THE CREATE LABELS PART!\n",
    "\n",
    "# Which kind of AUC would you like to use?\n",
    "AUC = 'unweighted'\n",
    "#AUC = 'weighted'\n",
    "#WHEN YOU CHANGE AUC, YOU DON'T HAVE TO RERUN ANYTHING!\n",
    "\n",
    "# The output filenames\n",
    "FILENAME_OPTIONS = CHANNEL + '_' + LABELS + '_' + AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_tt = uproot.open(\"/eos/user/k/kgalambo/SWAN_projects/Masters_CP_Kristof_2/MVAFILE_AllHiggs_tt.root\")[\"ntuple\"]\n",
    "\n",
    "variables = [\n",
    "            \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\",\n",
    "            \"aco_angle_1\",\n",
    "            \"aco_angle_5\", \"aco_angle_6\", \"aco_angle_7\",\n",
    "            \"mva_dm_1\",\"mva_dm_2\",\n",
    "            \"tau_decay_mode_1\",\"tau_decay_mode_2\",\n",
    "            \"ip_x_1\", \"ip_y_1\", \"ip_z_1\", \"ip_x_2\", \"ip_y_2\", \"ip_z_2\", # need impact parameter for aco_angle_6\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", # charged pion 1\n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", # charged pion 2\n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\", # neutral pion 1\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", # neutral pion 2\n",
    "            \"y_1_1\", \"y_1_2\" # y variables\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line takes a long time!\n",
    "df = tree_tt.pandas.df(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHANNEL == 'rho_rho':\n",
    "    # select only rho-rho events\n",
    "    df_filtered = df[(df['mva_dm_1']==1) & (df['mva_dm_2']==1) & (df[\"tau_decay_mode_1\"] == 1) & (df[\"tau_decay_mode_2\"] == 1)]\n",
    "\n",
    "elif CHANNEL == 'rho_a1':\n",
    "    # select only rho-a1 events\n",
    "    df_filtered = df[(df['mva_dm_1']==1) & (df['mva_dm_2']==10) & (df[\"tau_decay_mode_1\"] == 1)]\n",
    "\n",
    "elif CHANNEL == 'a1_a1':\n",
    "    # select only a1-a1 events\n",
    "    df_filtered = df[(df['mva_dm_1']==10) & (df['mva_dm_2']==10)]\n",
    "    \n",
    "else:\n",
    "    print('CHANNEL not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels y\n",
    "\n",
    "# necessary for binary2 only:\n",
    "df_filtered_ps = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2)]\n",
    "df_filtered_sm = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_sm\"]/2)]\n",
    "\n",
    "if LABELS == 'continuous':\n",
    "    # non-binary\n",
    "    y = df_filtered[\"wt_cp_sm\"] / (df_filtered[\"wt_cp_ps\"] + df_filtered[\"wt_cp_sm\"])\n",
    "\n",
    "elif LABELS == 'binary1':\n",
    "    # binary method 1\n",
    "    y = (~(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2).to_numpy()).astype(int)\n",
    "\n",
    "elif LABELS == 'binary2':\n",
    "    # binary method 2\n",
    "    y_sm = pd.DataFrame(np.ones(df_filtered_sm.shape[0]))\n",
    "    y_ps = pd.DataFrame(np.zeros(df_filtered_ps.shape[0]))\n",
    "    y = pd.concat([y_sm, y_ps]).to_numpy()\n",
    "\n",
    "else:\n",
    "    print('LABELS not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = df_filtered[\"wt_cp_sm\"].to_numpy()\n",
    "w_b = df_filtered[\"wt_cp_ps\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The particle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse particle information\n",
    "#columns = ['E', 'px', 'py', 'pz']\n",
    "\n",
    "pi_1 = df_filtered[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_2 = df_filtered[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "pi0_1 = df_filtered[['pi0_E_1', \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\"]].to_numpy()\n",
    "pi0_2 = df_filtered[['pi0_E_2', \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct resonance 4 momentum\n",
    "rho_1 = pi_1 + pi0_1\n",
    "rho_2 = pi_2 + pi0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate invariant masses\n",
    "rho_1_m2 = rho_1[:, 0]**2 - rho_1[:, 1]**2 - rho_1[:, 2]**2 - rho_1[:, 3]**2\n",
    "rho_2_m2 = rho_2[:, 0]**2 - rho_2[:, 1]**2 - rho_2[:, 2]**2 - rho_2[:, 3]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = Momentum4(pi_1[:, 0], pi_1[:, 1], pi_1[:, 2], pi_1[:, 3]) # p3 = charged pion 1\n",
    "p4 = Momentum4(pi_2[:, 0], pi_2[:, 1], pi_2[:, 2], pi_2[:, 3]) # p4 = charged pion 2\n",
    "p1 = Momentum4(pi0_1[:, 0], pi0_1[:, 1], pi0_1[:, 2], pi0_1[:, 3]) # p1 = neutral pion 1\n",
    "p2 = Momentum4(pi0_2[:, 0], pi0_2[:, 1], pi0_2[:, 2], pi0_2[:, 3]) # p2 = neutral pion 2\n",
    "rest_frame = p1 + p2 + p3 + p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_boosted = p1.boost_particle(-rest_frame)\n",
    "p3_boosted = p3.boost_particle(-rest_frame)\n",
    "p2_boosted = p2.boost_particle(-rest_frame)\n",
    "p4_boosted = p4.boost_particle(-rest_frame)\n",
    "\n",
    "r1_boosted = p1_boosted + p3_boosted\n",
    "r2_boosted = p2_boosted + p4_boosted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of other aco_angles\n",
    "\n",
    "<font size=4 color='red'>__You can skip this part__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_1 = df_filtered['y_1_1'].to_numpy()\n",
    "y_1_2 = df_filtered['y_1_2'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aco(p1_boosted, p2_boosted, p3_boosted, p4_boosted):\n",
    "    \"\"\"\n",
    "    The input 4-vectors should be:\n",
    "    Momentum4 instances with shape 4 by ?\n",
    "    The energy (first) row doesn't matter, can be anything\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    phi_cps = []\n",
    "    def unit(vect):\n",
    "        return vect / np.linalg.norm(vect)\n",
    "    for pp1, pp2, pp3, pp4 in zip(p1_boosted[:].T, p2_boosted[:].T, p3_boosted[:].T, p4_boosted[:].T):\n",
    "        n1 = pp1[1:] - np.dot(pp1[1:], unit(pp3[1:])) * unit(pp3[1:])\n",
    "        n2 = pp2[1:] - np.dot(pp2[1:], unit(pp4[1:])) * unit(pp4[1:])\n",
    "        n1 = unit(n1)\n",
    "        n2 = unit(n2)\n",
    "\n",
    "        angle = np.arccos(np.dot(n1, n2))\n",
    "        sign = np.dot(unit(pp4[1:]), np.cross(n1, n2))\n",
    "\n",
    "        # shift 1\n",
    "        if sign < 0:\n",
    "            angle = 2 * np.pi - angle\n",
    "\n",
    "        phi_cps.append(angle)\n",
    "        if i%100000==0:\n",
    "            print('finished instance', i)\n",
    "        i += 1\n",
    "        \n",
    "        # this part should be commented out\n",
    "        if y_1_1[i] * y_1_2[i] < 0:\n",
    "            if angle < np.pi:\n",
    "                angle += np.pi\n",
    "            else:\n",
    "                angle -= np.pi\n",
    "        \n",
    "    return phi_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_1 = df_filtered[[\"ip_x_1\", \"ip_y_1\", \"ip_z_1\"]].to_numpy()\n",
    "ip_2 = df_filtered[[\"ip_x_2\", \"ip_y_2\", \"ip_z_2\"]].to_numpy()\n",
    "zeros = np.reshape(np.zeros(len(ip_1)), (-1, 1))\n",
    "ip_1 = np.concatenate([zeros, ip_1], axis=1)\n",
    "ip_2 = np.concatenate([zeros, ip_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished instance 0\n",
      "finished instance 100000\n",
      "finished instance 200000\n",
      "finished instance 300000\n",
      "finished instance 400000\n",
      "finished instance 500000\n",
      "finished instance 600000\n"
     ]
    }
   ],
   "source": [
    "# calculate aco_angle_1\n",
    "#phi_cps = calc_aco(p1_boosted, p2_boosted, p3_boosted, p4_boosted)\n",
    "\n",
    "# calculate aco_angle_6\n",
    "aco_6_calculated = calc_aco(ip_1.T, ip_2.T, p3_boosted, p4_boosted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare calculated aco_angle_6-s\n",
    "\n",
    "<font size=4 color='red'>__You can skip this part__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS UNBOOSTED, SO GIVES WRONG RESULTS\n",
    "\n",
    "aco_angle_6_ps = df_filtered_ps['aco_angle_6'].to_numpy()\n",
    "aco_angle_6_sm = df_filtered_sm['aco_angle_6'].to_numpy()\n",
    "\n",
    "pi_1_ps = df_filtered_ps[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_1_sm = df_filtered_sm[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_2_ps = df_filtered_ps[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "pi_2_sm = df_filtered_sm[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "ip_1_ps = df_filtered_ps[[\"ip_x_1\", \"ip_y_1\", \"ip_z_1\"]].to_numpy()\n",
    "ip_1_sm = df_filtered_sm[[\"ip_x_1\", \"ip_y_1\", \"ip_z_1\"]].to_numpy()\n",
    "ip_2_ps = df_filtered_ps[[\"ip_x_2\", \"ip_y_2\", \"ip_z_2\"]].to_numpy()\n",
    "ip_2_sm = df_filtered_sm[[\"ip_x_2\", \"ip_y_2\", \"ip_z_2\"]].to_numpy()\n",
    "zeros_ps = np.reshape(np.zeros(len(ip_1_ps)), (-1, 1))\n",
    "zeros_sm = np.reshape(np.zeros(len(ip_1_sm)), (-1, 1))\n",
    "ip_1_ps = np.concatenate([zeros_ps, ip_1_ps], axis=1)\n",
    "ip_1_sm = np.concatenate([zeros_sm, ip_1_sm], axis=1)\n",
    "ip_2_ps = np.concatenate([zeros_ps, ip_2_ps], axis=1)\n",
    "ip_2_sm = np.concatenate([zeros_sm, ip_2_sm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BOOSTED ACCORDING TO ALIE'S METHOD, GIVES ALMOST GOOD RESULTS\n",
    "\n",
    "aco_angle_6_ps = df_filtered_ps['aco_angle_6'].to_numpy()\n",
    "aco_angle_6_sm = df_filtered_sm['aco_angle_6'].to_numpy()\n",
    "\n",
    "pi_1_ps = Momentum4(df_filtered_ps[\"pi_E_1\"],df_filtered_ps[\"pi_px_1\"],df_filtered_ps[\"pi_py_1\"],df_filtered_ps[\"pi_pz_1\"])\n",
    "pi_1_sm = Momentum4(df_filtered_sm[\"pi_E_1\"],df_filtered_sm[\"pi_px_1\"],df_filtered_sm[\"pi_py_1\"],df_filtered_sm[\"pi_pz_1\"])\n",
    "pi_2_ps = Momentum4(df_filtered_ps[\"pi_E_2\"],df_filtered_ps[\"pi_px_2\"],df_filtered_ps[\"pi_py_2\"],df_filtered_ps[\"pi_pz_2\"])\n",
    "pi_2_sm = Momentum4(df_filtered_sm[\"pi_E_2\"],df_filtered_sm[\"pi_px_2\"],df_filtered_sm[\"pi_py_2\"],df_filtered_sm[\"pi_pz_2\"])\n",
    "ip_1_ps = Momentum4(np.zeros(len(df_filtered_ps[\"ip_x_1\"])),df_filtered_ps[\"ip_x_1\"],df_filtered_ps[\"ip_y_1\"],df_filtered_ps[\"ip_z_1\"])\n",
    "ip_1_sm = Momentum4(np.zeros(len(df_filtered_sm[\"ip_x_1\"])),df_filtered_sm[\"ip_x_1\"],df_filtered_sm[\"ip_y_1\"],df_filtered_sm[\"ip_z_1\"])\n",
    "ip_2_ps = Momentum4(np.zeros(len(df_filtered_ps[\"ip_x_2\"])),df_filtered_ps[\"ip_x_2\"],df_filtered_ps[\"ip_y_2\"],df_filtered_ps[\"ip_z_2\"])\n",
    "ip_2_sm = Momentum4(np.zeros(len(df_filtered_sm[\"ip_x_2\"])),df_filtered_sm[\"ip_x_2\"],df_filtered_sm[\"ip_y_2\"],df_filtered_sm[\"ip_z_2\"])\n",
    "\n",
    "com_ps = Momentum4(pi_1_ps+pi_2_ps)\n",
    "com_sm = Momentum4(pi_1_sm+pi_2_sm)\n",
    "boost_ps = Momentum4(com_ps[0], -com_ps[1], -com_ps[2], -com_ps[3])\n",
    "boost_sm = Momentum4(com_sm[0], -com_sm[1], -com_sm[2], -com_sm[3])\n",
    "pi_1_ps = pi_1_ps.boost_particle(boost_ps)[:].T\n",
    "pi_1_sm = pi_1_sm.boost_particle(boost_sm)[:].T\n",
    "pi_2_ps = pi_2_ps.boost_particle(boost_ps)[:].T\n",
    "pi_2_sm = pi_2_sm.boost_particle(boost_sm)[:].T\n",
    "ip_1_ps = ip_1_ps.boost_particle(boost_ps)[:].T\n",
    "ip_1_sm = ip_1_sm.boost_particle(boost_sm)[:].T\n",
    "ip_2_ps = ip_2_ps.boost_particle(boost_ps)[:].T\n",
    "ip_2_sm = ip_2_sm.boost_particle(boost_sm)[:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323769, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_1_ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished instance 0\n",
      "finished instance 100000\n",
      "finished instance 200000\n",
      "finished instance 300000\n",
      "finished instance 0\n",
      "finished instance 100000\n",
      "finished instance 200000\n",
      "finished instance 300000\n"
     ]
    }
   ],
   "source": [
    "# calculate aco_angle_6\n",
    "aco_6_calculated_ps = calc_aco(ip_1_ps.T, ip_2_ps.T, pi_1_ps.T, pi_2_ps.T)\n",
    "aco_6_calculated_sm = calc_aco(ip_1_sm.T, ip_2_sm.T, pi_1_sm.T, pi_2_sm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to plot 'signal' vs 'background' for a specified variables\n",
    "# useful to check whether a variable gives some separation between\n",
    "# signal and background states\n",
    "def plot_signal_background(data1, data2, column,\n",
    "                        bins=100, x_uplim=0, **kwargs):\n",
    "\n",
    "    if \"alpha\" not in kwargs:\n",
    "        kwargs[\"alpha\"] = 0.5\n",
    "\n",
    "    df1 = data1[column]\n",
    "    df2 = data2[column]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df1 = df1.sample(3000, random_state=1234)\n",
    "    df2 = df2.sample(3000, random_state=1234)\n",
    "    low = max(min(df1.min(), df2.min()),-5)\n",
    "    high = max(df1.max(), df2.max())\n",
    "    if x_uplim != 0: high = x_uplim\n",
    "\n",
    "    ax.hist(df1, bins=bins, range=(low,high), **kwargs)\n",
    "    ax.hist(df2, bins=bins, range=(low,high), **kwargs)\n",
    "    if column == \"aco_angle_6\":\n",
    "        plt.title('given aco_angle_6 (true values)')\n",
    "    else:\n",
    "        plt.title(column)\n",
    "    \n",
    "    if x_uplim != 0:\n",
    "        ax.set_xlim(0,x_uplim)\n",
    "\n",
    "    # ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot my calculated aco_angle_6 values\n",
    "aco_6_calculated_ps_df = pd.DataFrame(aco_6_calculated_ps, columns=['aco_angle_6 calculated from low-level data'])\n",
    "aco_6_calculated_sm_df = pd.DataFrame(aco_6_calculated_sm, columns=['aco_angle_6 calculated from low-level data'])\n",
    "plot_signal_background(aco_6_calculated_ps_df, aco_6_calculated_sm_df, 'aco_angle_6 calculated from low-level data', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the given aco_angle_6 values\n",
    "aco_angle_6_ps_df = pd.DataFrame(aco_angle_6_ps, columns=['aco_angle_6'])\n",
    "aco_angle_6_sm_df = pd.DataFrame(aco_angle_6_sm, columns=['aco_angle_6'])\n",
    "plot_signal_background(aco_angle_6_ps_df, aco_angle_6_sm_df, 'aco_angle_6', bins=100)\n",
    "\n",
    "# THIS ONLY WORKS FOR THE RHO-RHO CHANNEL I GUESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a52f3bf6fffb>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  unit1 = (r1_boosted[1:, :] / np.linalg.norm(r1_boosted[1:, :], axis=0)).transpose()\n",
      "<ipython-input-13-a52f3bf6fffb>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  unit2 = (r2_boosted[1:, :] / np.linalg.norm(r2_boosted[1:, :], axis=0)).transpose()\n"
     ]
    }
   ],
   "source": [
    "# unit vectors along the momenta of the primary resonances\n",
    "unit1 = (r1_boosted[1:, :] / np.linalg.norm(r1_boosted[1:, :], axis=0)).transpose()\n",
    "unit2 = (r2_boosted[1:, :] / np.linalg.norm(r2_boosted[1:, :], axis=0)).transpose()\n",
    "\n",
    "# probably there's a faster way of doing this\n",
    "zaxis = np.array([np.array([0., 0., 1.]) for _ in range(len(unit1))])\n",
    "\n",
    "axes1 = np.cross(unit1, zaxis)\n",
    "axes2 = np.cross(unit2, zaxis)\n",
    "\n",
    "dotproduct1 = (unit1*zaxis).sum(1)\n",
    "angles1 = np.arccos(dotproduct1)\n",
    "dotproduct2 = (unit2*zaxis).sum(1)\n",
    "angles2 = np.arccos(dotproduct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rotated test_vector is:\n",
      "[ 2.22044605e-16  0.00000000e+00 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / np.dot(axis, axis)**0.5\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def rotate(vect, axis, theta):\n",
    "    return np.dot(rotation_matrix(axis, theta), vect)\n",
    "\n",
    "test_vector = [1, 0, 0]\n",
    "test_axis = [0, 1, 0]\n",
    "test_angle = np.pi/2\n",
    "\n",
    "print('The rotated test_vector is:')\n",
    "print(rotate(test_vector, test_axis, test_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished rotating 3-vector 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-c5ddbe905209>:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  axis = axis / np.dot(axis, axis)**0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished rotating 3-vector 100000\n",
      "finished rotating 3-vector 200000\n",
      "finished rotating 3-vector 300000\n"
     ]
    }
   ],
   "source": [
    "# it would be nice to be able to do the rotation in a vectorized form, like this:\n",
    "#p1rot = rotate(p1_boosted[1:, :].transpose(), axes1, angles1)\n",
    "\n",
    "p1rot = []\n",
    "p2rot = []\n",
    "p3rot = []\n",
    "p4rot = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1rot.append(rotate(p1_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p2rot.append(rotate(p2_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p3rot.append(rotate(p3_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p4rot.append(rotate(p4_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    if i%100000==0:\n",
    "        print('finished rotating 3-vector', i)\n",
    "p1rot = np.array(p1rot)\n",
    "p2rot = np.array(p2rot)\n",
    "p3rot = np.array(p3rot)\n",
    "p4rot = np.array(p4rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished getting rotated 4-vector 0\n",
      "finished getting rotated 4-vector 100000\n",
      "finished getting rotated 4-vector 200000\n",
      "finished getting rotated 4-vector 300000\n"
     ]
    }
   ],
   "source": [
    "# this should be vectorized as well\n",
    "p1_rotated = []\n",
    "p2_rotated = []\n",
    "p3_rotated = []\n",
    "p4_rotated = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1_rotated.append([p1_boosted[0, i], p1rot[i, 0], p1rot[i, 1], p1rot[i, 2]])\n",
    "    p2_rotated.append([p2_boosted[0, i], p2rot[i, 0], p2rot[i, 1], p2rot[i, 2]])\n",
    "    p3_rotated.append([p3_boosted[0, i], p3rot[i, 0], p3rot[i, 1], p3rot[i, 2]])\n",
    "    p4_rotated.append([p4_boosted[0, i], p4rot[i, 0], p4rot[i, 1], p4rot[i, 2]])\n",
    "    if i%100000==0:\n",
    "        print('finished getting rotated 4-vector', i)\n",
    "p1_rotated = np.array(p1_rotated).transpose()\n",
    "p2_rotated = np.array(p2_rotated).transpose()\n",
    "p3_rotated = np.array(p3_rotated).transpose()\n",
    "p4_rotated = np.array(p4_rotated).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and labels\n",
    "\n",
    "aco_angle_1 = df_filtered['aco_angle_1'].to_numpy()\n",
    "y_1_1 = df_filtered['y_1_1'].to_numpy()\n",
    "y_1_2 = df_filtered['y_1_2'].to_numpy()\n",
    "\n",
    "aco_angle_5 = df_filtered['aco_angle_5'].to_numpy()\n",
    "aco_angle_6 = df_filtered['aco_angle_6'].to_numpy()\n",
    "aco_angle_7 = df_filtered['aco_angle_7'].to_numpy()\n",
    "\n",
    "# this will use the unrotated, boosted 4-vectors:\n",
    "E1 = p1_boosted[0]\n",
    "px1 = p1_boosted[1]\n",
    "py1 = p1_boosted[2]\n",
    "pz1 = p1_boosted[3]\n",
    "E2 = p2_boosted[0]\n",
    "px2 = p2_boosted[1]\n",
    "py2 = p2_boosted[2]\n",
    "pz2 = p2_boosted[3]\n",
    "E3 = p3_boosted[0]\n",
    "px3 = p3_boosted[1]\n",
    "py3 = p3_boosted[2]\n",
    "pz3 = p3_boosted[3]\n",
    "E4 = p4_boosted[0]\n",
    "px4 = p4_boosted[1]\n",
    "py4 = p4_boosted[2]\n",
    "pz4 = p4_boosted[3]\n",
    "\n",
    "# this will use the rotated, boosted 4-vectors:\n",
    "E1r = p1_rotated[0]\n",
    "px1r = p1_rotated[1]\n",
    "py1r = p1_rotated[2]\n",
    "pz1r = p1_rotated[3]\n",
    "E2r = p2_rotated[0]\n",
    "px2r = p2_rotated[1]\n",
    "py2r = p2_rotated[2]\n",
    "pz2r = p2_rotated[3]\n",
    "E3r = p3_rotated[0]\n",
    "px3r = p3_rotated[1]\n",
    "py3r = p3_rotated[2]\n",
    "pz3r = p3_rotated[3]\n",
    "E4r = p4_rotated[0]\n",
    "px4r = p4_rotated[1]\n",
    "py4r = p4_rotated[2]\n",
    "pz4r = p4_rotated[3]\n",
    "\n",
    "# y is defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_aco_angles_added = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, w_a, w_b, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    w_a = w_a[~nan_mask_y]\n",
    "    w_b = w_b[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y, w_a, w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple NN\n",
    "def baseline_model2(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(38, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model\n",
    "\n",
    "def baseline_model(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(300, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define a function to plot the ROC curves - just makes the roc_curve look nicer than the default\n",
    "def plot_roc_curve(fpr, tpr, auc, filename='roc_untitled'):\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.grid()\n",
    "    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n",
    "            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n",
    "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "    ax.plot(lims, lims, 'k--')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.savefig('paper/' + filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(i):\n",
    "    if i==1:\n",
    "        X = np.reshape(aco_angle_1, (-1, 1))\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==2:\n",
    "        X = np.stack([aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==3:\n",
    "        X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==4:\n",
    "        X = np.stack([aco_angle_1, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==5:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "    if i==6:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "\n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if i==1:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7], axis=1)\n",
    "        if i==2:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==3:\n",
    "            X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==4:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==5:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==6:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        \n",
    "        \n",
    "    return X\n",
    "\n",
    "def run_config(config_num, y, w_a, w_b, epoch_number, batch_number):\n",
    "    X = load_config(config_num)\n",
    "\n",
    "    want_filter_nans = False\n",
    "    if CHANNEL == 'rho_a1' or CHANNEL == 'a1_a1':\n",
    "        want_filter_nans = True\n",
    "    if want_filter_nans:\n",
    "        X, y, w_a, w_b = filter_nans(X, y, w_a, w_b, config_num)\n",
    "        \n",
    "    w_a_train, w_a_test, w_b_train, w_b_test  = train_test_split(w_a, w_b, test_size=0.2, random_state=123456)\n",
    "    \n",
    "    # split X and y into train and validation dataset \n",
    "\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=123456,\n",
    "        #stratify=y.values,\n",
    "    )\n",
    "    \n",
    "    # define early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # first run the training for simple case with just 1 variable\n",
    "    history = tf.keras.callbacks.History()\n",
    "\n",
    "    model = baseline_model(X.shape[1])\n",
    "\n",
    "    model.fit(\n",
    "                    X_train, y_train,\n",
    "                    batch_size=batch_number,\n",
    "                    epochs=epoch_number,\n",
    "                    callbacks=[history,early_stop],\n",
    "                    validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Extract number of run epochs from the training history\n",
    "    epochs = range(1, len(history.history[\"loss\"])+1)\n",
    "\n",
    "    # Extract loss on training and validation ddataset and plot them together\n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs, history.history[\"loss\"], \"o-\", label=\"Training\")\n",
    "    plt.plot(epochs, history.history[\"val_loss\"], \"o-\", label=\"Test\")\n",
    "    plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.savefig('paper/history_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    plt.close()\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    # plot ROC curve for improved training\n",
    "    y_proba = model.predict_proba(X_test) # outputs two probabilties\n",
    "    \n",
    "    def stanley_auc():\n",
    "        #Stanley's way of calculating auc\n",
    "        y_pred_roc = model.predict(X_test) #for test dataset\n",
    "        #y_pred_roc = model.predict(X) # for full dataset\n",
    "        y_pred_roc_final = np.r_[y_pred_roc, y_pred_roc]\n",
    "        set_a = np.ones(len(y_pred_roc))\n",
    "        set_b = np.zeros(len(y_pred_roc))\n",
    "        y_label_roc = np.r_[set_a, set_b]\n",
    "        w_roc = np.r_[w_a_test, w_b_test] # for test dataset\n",
    "        #w_roc = np.r_[w_a, w_b] # for full dataset\n",
    "        #print('========================================')\n",
    "        #print(y_label_roc.shape)\n",
    "        #print(y_pred_roc_final.shape)\n",
    "        #print(w_roc.shape)\n",
    "        #print('========================================')\n",
    "        auc = roc_auc_score(y_label_roc, y_pred_roc_final, sample_weight=w_roc)\n",
    "        return auc\n",
    "    \n",
    "    if LABELS == 'continuous':\n",
    "        # the original way of calculating auc\n",
    "        y_binary = (y_test > 0.5) * 1.0\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_binary, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_binary, y_proba)\n",
    "        \n",
    "    if LABELS == 'binary1' or LABELS == 'binary2':\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        \n",
    "    plot_roc_curve(fpr, tpr, auc, 'roc_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    \n",
    "    f = open('paper/auc_' + FILENAME_OPTIONS + '.txt', 'a')\n",
    "    f.write(str(config_num) + ',' + str(auc) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(exp_no, epoch_no=50, batch_no=1000):\n",
    "    confs = [1, 2, 3, 4, 5, 6]\n",
    "    for i in range(exp_no):\n",
    "        for conf in confs:\n",
    "            run_config(conf, y, w_a.copy(), w_b.copy(), epoch_no, batch_no)\n",
    "            print('CONFIG', conf, 'DONE')\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print('##########################################################')\n",
    "        print('DONE ITERATION', i)\n",
    "        print('##########################################################')\n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 47.2230 - val_loss: 17.1797\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 16.1823 - val_loss: 29.5210\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 10.0541 - val_loss: 3.7355\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 4.9031 - val_loss: 7.1544\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 4.0665 - val_loss: 1.4546\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.0929 - val_loss: 7.4955\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.3881 - val_loss: 0.9464\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.0202 - val_loss: 0.9996\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.0670 - val_loss: 0.9398\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 4s 12ms/step - loss: 0.9983 - val_loss: 0.7250\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.2451 - val_loss: 3.0687\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.0103 - val_loss: 0.7105\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7411 - val_loss: 0.7710\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7991 - val_loss: 0.8061\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.8289 - val_loss: 0.7476\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.8413 - val_loss: 0.9040\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.8511 - val_loss: 0.7575\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7901 - val_loss: 0.7178\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7607 - val_loss: 0.7087\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7860 - val_loss: 0.8317\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7620 - val_loss: 0.7120\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 4s 12ms/step - loss: 0.7460 - val_loss: 0.7602\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7799 - val_loss: 0.7073\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7329 - val_loss: 0.6979\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7573 - val_loss: 0.7112\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7381 - val_loss: 0.7282\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7529 - val_loss: 0.7091\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7116 - val_loss: 0.7046\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 4s 12ms/step - loss: 0.7121 - val_loss: 0.6949\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7087 - val_loss: 0.6932\n",
      "CONFIG 1 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 36.2168 - val_loss: 3.7813\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 24.9799 - val_loss: 11.1730\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 12.2383 - val_loss: 18.7270\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 8.1765 - val_loss: 10.2678\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 3.3924 - val_loss: 1.3539\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.9801 - val_loss: 1.1169\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.0742 - val_loss: 3.2065\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.6914 - val_loss: 0.7087\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7760 - val_loss: 0.7201\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8341 - val_loss: 1.0703\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8811 - val_loss: 0.8301\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8492 - val_loss: 0.8335\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8417 - val_loss: 1.0644\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8581 - val_loss: 0.9240\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7916 - val_loss: 0.7139\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7919 - val_loss: 0.9805\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.0082 - val_loss: 0.6987\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7236 - val_loss: 0.6938\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7197 - val_loss: 0.7170\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7273 - val_loss: 0.7438\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7244 - val_loss: 0.7071\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7235 - val_loss: 0.6951\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7157 - val_loss: 0.6963\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7048 - val_loss: 0.6961\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7116 - val_loss: 0.6943\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7066 - val_loss: 0.7071\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7019 - val_loss: 0.6934\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6978 - val_loss: 0.6934\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6982 - val_loss: 0.6978\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6954 - val_loss: 0.6974\n",
      "CONFIG 2 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.7054 - val_loss: 0.6959\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6963 - val_loss: 0.6942\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6954 - val_loss: 0.6949\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6942 - val_loss: 0.6991\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6940 - val_loss: 0.6932\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6938 - val_loss: 0.6935\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6937 - val_loss: 0.6936\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 5s 17ms/step - loss: 0.6934 - val_loss: 0.6934\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.6933 - val_loss: 0.6933\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6933 - val_loss: 0.6932\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6932 - val_loss: 0.6933\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6932 - val_loss: 0.6932\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6931 - val_loss: 0.6929\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6929 - val_loss: 0.6926\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6926 - val_loss: 0.6923\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6922 - val_loss: 0.6920\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6920 - val_loss: 0.6923\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6920 - val_loss: 0.6914\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6918 - val_loss: 0.6921\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6916 - val_loss: 0.6917\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.6914 - val_loss: 0.6910\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6914 - val_loss: 0.6913\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6912 - val_loss: 0.6908\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6912 - val_loss: 0.6912\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6910 - val_loss: 0.6907\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6909 - val_loss: 0.6906\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6909 - val_loss: 0.6909\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6908 - val_loss: 0.6910\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6908 - val_loss: 0.6904\n",
      "CONFIG 3 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 7s 25ms/step - loss: 50.0436 - val_loss: 3.0774\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 7s 23ms/step - loss: 17.4526 - val_loss: 23.1263\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 11.2540 - val_loss: 9.0480\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 7.2878 - val_loss: 0.8994\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 5s 16ms/step - loss: 3.7237 - val_loss: 4.8235\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 6.1177 - val_loss: 6.3369\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 1.5387 - val_loss: 0.7483\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 7s 24ms/step - loss: 1.2064 - val_loss: 2.2927\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 1.2439 - val_loss: 0.7861\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.8492 - val_loss: 0.9494\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.8890 - val_loss: 0.8780\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.9212 - val_loss: 0.7242\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.7990 - val_loss: 1.3616\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.1313 - val_loss: 0.7092\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7196 - val_loss: 0.8007\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7337 - val_loss: 0.7277\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7447 - val_loss: 0.7369\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7272 - val_loss: 0.7324\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7799 - val_loss: 0.8354\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7741 - val_loss: 0.7063\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7616 - val_loss: 0.6982\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7485 - val_loss: 0.7345\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7716 - val_loss: 0.7050\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7341 - val_loss: 0.7112\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 18ms/step - loss: 0.7348 - val_loss: 0.7012\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7310 - val_loss: 0.6958\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7156 - val_loss: 0.6966\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7137 - val_loss: 0.7759\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7153 - val_loss: 0.6984\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7149 - val_loss: 0.7947\n",
      "CONFIG 4 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 37.4921 - val_loss: 26.5341\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 21.2985 - val_loss: 13.6436\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 9.4956 - val_loss: 10.6581\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 7.1176 - val_loss: 7.5066\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 3.1405 - val_loss: 0.7237\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.5137 - val_loss: 2.2157\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 2.4591 - val_loss: 9.9824\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.7835 - val_loss: 0.7370\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.4670 - val_loss: 1.2239\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.9529 - val_loss: 0.8133\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 18ms/step - loss: 0.9284 - val_loss: 0.6963\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.0745 - val_loss: 0.7010\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8674 - val_loss: 0.7276\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8694 - val_loss: 0.8942\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8402 - val_loss: 0.7868\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8548 - val_loss: 0.9596\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7929 - val_loss: 0.8463\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8023 - val_loss: 0.6934\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8066 - val_loss: 0.7324\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7787 - val_loss: 0.8261\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7603 - val_loss: 0.8174\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7977 - val_loss: 0.8218\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 5s 18ms/step - loss: 0.7445 - val_loss: 0.7062\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7415 - val_loss: 0.6965\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7252 - val_loss: 0.7081\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7173 - val_loss: 0.7675\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7253 - val_loss: 0.6932\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7272 - val_loss: 0.7262\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7143 - val_loss: 0.7094\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7156 - val_loss: 0.6932\n",
      "CONFIG 5 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 33.8241 - val_loss: 24.1809\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 23.1632 - val_loss: 8.8852\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 7.5533 - val_loss: 14.1364\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 4.3468 - val_loss: 1.1492\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 5.5151 - val_loss: 2.2354\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.1643 - val_loss: 0.8875\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.9815 - val_loss: 0.7237\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.0156 - val_loss: 1.7717\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 1.6057 - val_loss: 2.8870\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 1.5301 - val_loss: 0.7179\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7797 - val_loss: 0.8574\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8092 - val_loss: 0.8660\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 5s 18ms/step - loss: 0.8248 - val_loss: 1.2567\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8159 - val_loss: 1.2272\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.8236 - val_loss: 0.7792\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7660 - val_loss: 0.6965\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7709 - val_loss: 0.6936\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7676 - val_loss: 0.7315\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7510 - val_loss: 0.7616\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7561 - val_loss: 0.6933\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7280 - val_loss: 0.7407\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7415 - val_loss: 0.7010\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7303 - val_loss: 0.7294\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7128 - val_loss: 0.7148\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.7109 - val_loss: 0.6984\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7094 - val_loss: 0.6933\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7144 - val_loss: 0.6934\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7140 - val_loss: 0.6932\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6990 - val_loss: 0.6995\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7010 - val_loss: 0.6935\n",
      "CONFIG 6 DONE\n",
      "\n",
      "\n",
      "\n",
      "##########################################################\n",
      "DONE ITERATION 0\n",
      "##########################################################\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run 8 experiments\n",
    "#run_experiments(8)\n",
    "\n",
    "run_experiments(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
