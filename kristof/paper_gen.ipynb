{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating https://arxiv.org/pdf/1608.02609.pdf first for $\\rho$-$\\rho$ decays\n",
    "\n",
    "## Inputs:\n",
    "- Invariant masses of intermediate resonances  \n",
    "- Acoplanarity angles\n",
    "- Variables $y_i^+$ ($y_k^-$)\n",
    "- 4 momentum of visible decay products\n",
    "- 4 momentum of intermediate resonances\n",
    "    - If cascade decays, need to provide 4-momenta of all $\\pi^+\\pi^-$ pairs which can form the resonances\n",
    "- Need to boost all four vectors where primary resonances are aligned along the z-axis.\n",
    "- Normalise all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n"
     ]
    }
   ],
   "source": [
    "import uproot \n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Position4\n",
    "from lbn_modified import LBN, LBNLayer\n",
    "from ROOT import TLorentzVector, TVector3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important options\n",
    "\n",
    "# Which channel would you like to use?\n",
    "CHANNEL = 'rho_rho'\n",
    "#CHANNEL = 'rho_a1'\n",
    "#CHANNEL = 'a1_a1'\n",
    "# WARNING: IF YOU CHANGE CHANNEL, YOU HAVE TO RERUN THE WHOLE CODE FROM THE CHANNEL READ-IN!\n",
    "\n",
    "# Which kind of labels do you want to use?\n",
    "LABELS = 'continuous'\n",
    "#LABELS = 'binary1'\n",
    "#LABELS = 'binary2'\n",
    "#WARNING: IF YOU CHANGE LABELS, YOU HAVE TO RERUN THE CREATE LABELS PART!\n",
    "\n",
    "# Which kind of AUC would you like to use?\n",
    "#AUC = 'unweighted'\n",
    "AUC = 'weighted'\n",
    "#WHEN YOU CHANGE AUC, YOU DON'T HAVE TO RERUN ANYTHING!\n",
    "\n",
    "# The output filenames\n",
    "FILENAME_OPTIONS = CHANNEL + '_' + LABELS + '_' + AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_tt = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_GEN_AllHiggs_tt.root\")[\"ntuple\"]\n",
    "\n",
    "# with these variables, the kernel dies\n",
    "variables = [\n",
    "            \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\",\n",
    "            \"dm_1\", \"dm_2\",\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", # charged pion 1\n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", # charged pion 2\n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\", # neutral pion 1\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", # neutral pion 2\n",
    "            ]\n",
    "\n",
    "# with these variables the code runs, but then we don't have selectors...\n",
    "only_4vectors = [\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", # charged pion 1\n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", # charged pion 2\n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\", # neutral pion 1\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", # neutral pion 2\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line takes a long time!\n",
    "df = tree_tt.pandas.df(variables) # this runs for some time until the kernel dies\n",
    "#df = tree_tt.pandas.df(only_4vectors) # this runs but then we don't have selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"./pickled_df.pkl\") # this is the full dataset and it kills the kernel\n",
    "df = pd.read_pickle('./pickled_df_500000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHANNEL == 'rho_rho':\n",
    "    # select only rho-rho events\n",
    "    df_filtered = df[(df['dm_1']==1) & (df['dm_2']==1)]\n",
    "\n",
    "elif CHANNEL == 'rho_a1':\n",
    "    # select only rho-a1 events\n",
    "    df_filtered = df[(df['dm_1']==1) & (df['dm_2']==10)]\n",
    "\n",
    "elif CHANNEL == 'a1_a1':\n",
    "    # select only a1-a1 events\n",
    "    df_filtered = df[(df['dm_1']==10) & (df['dm_2']==10)]\n",
    "    \n",
    "else:\n",
    "    print('CHANNEL not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels y\n",
    "\n",
    "# necessary for binary2 only:\n",
    "df_filtered_ps = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2)]\n",
    "df_filtered_sm = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_sm\"]/2)]\n",
    "\n",
    "if LABELS == 'continuous':\n",
    "    # non-binary\n",
    "    y = df_filtered[\"wt_cp_sm\"] / (df_filtered[\"wt_cp_ps\"] + df_filtered[\"wt_cp_sm\"])\n",
    "\n",
    "elif LABELS == 'binary1':\n",
    "    # binary method 1\n",
    "    y = (~(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2).to_numpy()).astype(int)\n",
    "\n",
    "elif LABELS == 'binary2':\n",
    "    # binary method 2\n",
    "    y_sm = pd.DataFrame(np.ones(df_filtered_sm.shape[0]))\n",
    "    y_ps = pd.DataFrame(np.zeros(df_filtered_ps.shape[0]))\n",
    "    y = pd.concat([y_sm, y_ps]).to_numpy()\n",
    "\n",
    "else:\n",
    "    print('LABELS not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = df_filtered[\"wt_cp_sm\"].to_numpy()\n",
    "w_b = df_filtered[\"wt_cp_ps\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The particle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse particle information\n",
    "#columns = ['E', 'px', 'py', 'pz']\n",
    "\n",
    "pi_1 = df_filtered[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_2 = df_filtered[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "pi0_1 = df_filtered[['pi0_E_1', \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\"]].to_numpy()\n",
    "pi0_2 = df_filtered[['pi0_E_2', \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct resonance 4 momentum\n",
    "rho_1 = pi_1 + pi0_1\n",
    "rho_2 = pi_2 + pi0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate invariant masses\n",
    "rho_1_m2 = rho_1[:, 0]**2 - rho_1[:, 1]**2 - rho_1[:, 2]**2 - rho_1[:, 3]**2\n",
    "rho_2_m2 = rho_2[:, 0]**2 - rho_2[:, 1]**2 - rho_2[:, 2]**2 - rho_2[:, 3]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = Momentum4(pi_1[:, 0], pi_1[:, 1], pi_1[:, 2], pi_1[:, 3]) # p3 = charged pion 1\n",
    "p4 = Momentum4(pi_2[:, 0], pi_2[:, 1], pi_2[:, 2], pi_2[:, 3]) # p4 = charged pion 2\n",
    "p1 = Momentum4(pi0_1[:, 0], pi0_1[:, 1], pi0_1[:, 2], pi0_1[:, 3]) # p1 = neutral pion 1\n",
    "p2 = Momentum4(pi0_2[:, 0], pi0_2[:, 1], pi0_2[:, 2], pi0_2[:, 3]) # p2 = neutral pion 2\n",
    "rest_frame = p1 + p2 + p3 + p4\n",
    "boost = Momentum4(rest_frame[0], -rest_frame[1], -rest_frame[2], -rest_frame[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_boosted = p1.boost_particle(boost)\n",
    "p3_boosted = p3.boost_particle(boost)\n",
    "p2_boosted = p2.boost_particle(boost)\n",
    "p4_boosted = p4.boost_particle(boost)\n",
    "\n",
    "r1_boosted = p1_boosted + p3_boosted\n",
    "r2_boosted = p2_boosted + p4_boosted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the high-level variables\n",
    "\n",
    " - aco_angle_1\n",
    " - y_1_1, y_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_1_1 = (charged pion 1 energy - neutral pion 1 energy) / (charged pion 1 energy + neutral pion 1 energy)\n",
    "# y_1_2 calculated in a similar way replacing 1 with 2\n",
    "y_1_1 = (p3_boosted[0] - p1_boosted[0])/(p3_boosted[0] + p1_boosted[0])\n",
    "y_1_2 = (p4_boosted[0] - p2_boosted[0])/(p4_boosted[0] + p2_boosted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151151,)\n",
      "(4, 151151)\n",
      "0 0\n",
      "1 1\n",
      "2 2\n"
     ]
    }
   ],
   "source": [
    "print(y_1_1[:].shape)\n",
    "print(p1_boosted[:].shape)\n",
    "\n",
    "for a, b in zip(list(range(5)), list(range(3))):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aco(p1_boosted, p2_boosted, p3_boosted, p4_boosted):\n",
    "    \"\"\"\n",
    "    The input 4-vectors should be:\n",
    "    Momentum4 instances with shape 4 by ?\n",
    "    The energy (first) row doesn't matter, can be anything\n",
    "    assumes y_1_1 and y_1_2 are known as global variables\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    phi_cps = []\n",
    "    def unit(vect):\n",
    "        return vect / np.linalg.norm(vect)\n",
    "    for pp1, pp2, pp3, pp4 in zip(p1_boosted[:].T, p2_boosted[:].T, p3_boosted[:].T, p4_boosted[:].T):\n",
    "        n1 = pp1[1:] - np.dot(pp1[1:], unit(pp3[1:])) * unit(pp3[1:])\n",
    "        n2 = pp2[1:] - np.dot(pp2[1:], unit(pp4[1:])) * unit(pp4[1:])\n",
    "        n1 = unit(n1)\n",
    "        n2 = unit(n2)\n",
    "\n",
    "        angle = np.arccos(np.dot(n1, n2))\n",
    "        sign = np.dot(unit(pp4[1:]), np.cross(n1, n2))\n",
    "\n",
    "        # shift 1\n",
    "        if sign < 0:\n",
    "            angle = 2 * np.pi - angle\n",
    "        \n",
    "        # this part should be commented out\n",
    "        if y_1_1[i] * y_1_2[i] < 0:\n",
    "            if angle < np.pi:\n",
    "                angle += np.pi\n",
    "            else:\n",
    "                angle -= np.pi\n",
    "        \n",
    "        phi_cps.append(angle)\n",
    "        if i%100000==0:\n",
    "            print('finished instance', i)\n",
    "        i += 1\n",
    "    return phi_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished instance 0\n",
      "finished instance 100000\n"
     ]
    }
   ],
   "source": [
    "# calculate aco_angle_1\n",
    "aco_angle_1 = calc_aco(p1_boosted, p2_boosted, p3_boosted, p4_boosted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit vectors along the momenta of the primary resonances\n",
    "unit1 = (r1_boosted[1:, :] / np.linalg.norm(r1_boosted[1:, :], axis=0)).transpose()\n",
    "unit2 = (r2_boosted[1:, :] / np.linalg.norm(r2_boosted[1:, :], axis=0)).transpose()\n",
    "\n",
    "# probably there's a faster way of doing this\n",
    "zaxis = np.array([np.array([0., 0., 1.]) for _ in range(len(unit1))])\n",
    "\n",
    "axes1 = np.cross(unit1, zaxis)\n",
    "axes2 = np.cross(unit2, zaxis)\n",
    "\n",
    "dotproduct1 = (unit1*zaxis).sum(1)\n",
    "angles1 = np.arccos(dotproduct1)\n",
    "dotproduct2 = (unit2*zaxis).sum(1)\n",
    "angles2 = np.arccos(dotproduct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rotated test_vector is:\n",
      "[ 2.22044605e-16  0.00000000e+00 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / np.dot(axis, axis)**0.5\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def rotate(vect, axis, theta):\n",
    "    return np.dot(rotation_matrix(axis, theta), vect)\n",
    "\n",
    "test_vector = [1, 0, 0]\n",
    "test_axis = [0, 1, 0]\n",
    "test_angle = np.pi/2\n",
    "\n",
    "print('The rotated test_vector is:')\n",
    "print(rotate(test_vector, test_axis, test_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished rotating 3-vector 0\n",
      "finished rotating 3-vector 100000\n"
     ]
    }
   ],
   "source": [
    "# it would be nice to be able to do the rotation in a vectorized form, like this:\n",
    "#p1rot = rotate(p1_boosted[1:, :].transpose(), axes1, angles1)\n",
    "\n",
    "p1rot = []\n",
    "p2rot = []\n",
    "p3rot = []\n",
    "p4rot = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1rot.append(rotate(p1_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p2rot.append(rotate(p2_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p3rot.append(rotate(p3_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p4rot.append(rotate(p4_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    if i%100000==0:\n",
    "        print('finished rotating 3-vector', i)\n",
    "p1rot = np.array(p1rot)\n",
    "p2rot = np.array(p2rot)\n",
    "p3rot = np.array(p3rot)\n",
    "p4rot = np.array(p4rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished getting rotated 4-vector 0\n",
      "finished getting rotated 4-vector 100000\n"
     ]
    }
   ],
   "source": [
    "# this should be vectorized as well\n",
    "p1_rotated = []\n",
    "p2_rotated = []\n",
    "p3_rotated = []\n",
    "p4_rotated = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1_rotated.append([p1_boosted[0, i], p1rot[i, 0], p1rot[i, 1], p1rot[i, 2]])\n",
    "    p2_rotated.append([p2_boosted[0, i], p2rot[i, 0], p2rot[i, 1], p2rot[i, 2]])\n",
    "    p3_rotated.append([p3_boosted[0, i], p3rot[i, 0], p3rot[i, 1], p3rot[i, 2]])\n",
    "    p4_rotated.append([p4_boosted[0, i], p4rot[i, 0], p4rot[i, 1], p4rot[i, 2]])\n",
    "    if i%100000==0:\n",
    "        print('finished getting rotated 4-vector', i)\n",
    "p1_rotated = np.array(p1_rotated).transpose()\n",
    "p2_rotated = np.array(p2_rotated).transpose()\n",
    "p3_rotated = np.array(p3_rotated).transpose()\n",
    "p4_rotated = np.array(p4_rotated).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and labels\n",
    "\n",
    "# this will use the unrotated, boosted 4-vectors:\n",
    "E1 = p1_boosted[0]\n",
    "px1 = p1_boosted[1]\n",
    "py1 = p1_boosted[2]\n",
    "pz1 = p1_boosted[3]\n",
    "E2 = p2_boosted[0]\n",
    "px2 = p2_boosted[1]\n",
    "py2 = p2_boosted[2]\n",
    "pz2 = p2_boosted[3]\n",
    "E3 = p3_boosted[0]\n",
    "px3 = p3_boosted[1]\n",
    "py3 = p3_boosted[2]\n",
    "pz3 = p3_boosted[3]\n",
    "E4 = p4_boosted[0]\n",
    "px4 = p4_boosted[1]\n",
    "py4 = p4_boosted[2]\n",
    "pz4 = p4_boosted[3]\n",
    "\n",
    "# this will use the rotated, boosted 4-vectors:\n",
    "E1r = p1_rotated[0]\n",
    "px1r = p1_rotated[1]\n",
    "py1r = p1_rotated[2]\n",
    "pz1r = p1_rotated[3]\n",
    "E2r = p2_rotated[0]\n",
    "px2r = p2_rotated[1]\n",
    "py2r = p2_rotated[2]\n",
    "pz2r = p2_rotated[3]\n",
    "E3r = p3_rotated[0]\n",
    "px3r = p3_rotated[1]\n",
    "py3r = p3_rotated[2]\n",
    "pz3r = p3_rotated[3]\n",
    "E4r = p4_rotated[0]\n",
    "px4r = p4_rotated[1]\n",
    "py4r = p4_rotated[2]\n",
    "pz4r = p4_rotated[3]\n",
    "\n",
    "# y is defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_aco_angles_added = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, w_a, w_b, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    w_a = w_a[~nan_mask_y]\n",
    "    w_b = w_b[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y, w_a, w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple NN\n",
    "def baseline_model2(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(38, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model\n",
    "\n",
    "def baseline_model(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(300, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define a function to plot the ROC curves - just makes the roc_curve look nicer than the default\n",
    "def plot_roc_curve(fpr, tpr, auc, filename='roc_untitled'):\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.grid()\n",
    "    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n",
    "            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n",
    "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "    ax.plot(lims, lims, 'k--')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.savefig('paper_gen/' + filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(i):\n",
    "    if i==1:\n",
    "        X = np.reshape(aco_angle_1, (-1, 1))\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==2:\n",
    "        X = np.stack([aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==3:\n",
    "        X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==4:\n",
    "        X = np.stack([aco_angle_1, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==5:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "    if i==6:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "\n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if i==1:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7], axis=1)\n",
    "        if i==2:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==3:\n",
    "            X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==4:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==5:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==6:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        \n",
    "        \n",
    "    return X\n",
    "\n",
    "def run_config(config_num, y, w_a, w_b, epoch_number, batch_number):\n",
    "    X = load_config(config_num)\n",
    "\n",
    "    want_filter_nans = False\n",
    "    if CHANNEL == 'rho_a1' or CHANNEL == 'a1_a1':\n",
    "        want_filter_nans = True\n",
    "    if want_filter_nans:\n",
    "        X, y, w_a, w_b = filter_nans(X, y, w_a, w_b, config_num)\n",
    "        \n",
    "    w_a_train, w_a_test, w_b_train, w_b_test  = train_test_split(w_a, w_b, test_size=0.2, random_state=123456)\n",
    "    \n",
    "    # split X and y into train and validation dataset \n",
    "\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=123456,\n",
    "        #stratify=y.values,\n",
    "    )\n",
    "    \n",
    "    # define early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # first run the training for simple case with just 1 variable\n",
    "    history = tf.keras.callbacks.History()\n",
    "\n",
    "    model = baseline_model(X.shape[1])\n",
    "\n",
    "    model.fit(\n",
    "                    X_train, y_train,\n",
    "                    batch_size=batch_number,\n",
    "                    epochs=epoch_number,\n",
    "                    callbacks=[history,early_stop],\n",
    "                    validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Extract number of run epochs from the training history\n",
    "    epochs = range(1, len(history.history[\"loss\"])+1)\n",
    "\n",
    "    # Extract loss on training and validation ddataset and plot them together\n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs, history.history[\"loss\"], \"o-\", label=\"Training\")\n",
    "    plt.plot(epochs, history.history[\"val_loss\"], \"o-\", label=\"Test\")\n",
    "    plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.savefig('paper_gen/history_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    plt.close()\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    # plot ROC curve for improved training\n",
    "    y_proba = model.predict_proba(X_test) # outputs two probabilties\n",
    "    \n",
    "    def stanley_auc():\n",
    "        #Stanley's way of calculating auc\n",
    "        y_pred_roc = model.predict(X_test) #for test dataset\n",
    "        #y_pred_roc = model.predict(X) # for full dataset\n",
    "        y_pred_roc_final = np.r_[y_pred_roc, y_pred_roc]\n",
    "        set_a = np.ones(len(y_pred_roc))\n",
    "        set_b = np.zeros(len(y_pred_roc))\n",
    "        y_label_roc = np.r_[set_a, set_b]\n",
    "        w_roc = np.r_[w_a_test, w_b_test] # for test dataset\n",
    "        #w_roc = np.r_[w_a, w_b] # for full dataset\n",
    "        #print('========================================')\n",
    "        #print(y_label_roc.shape)\n",
    "        #print(y_pred_roc_final.shape)\n",
    "        #print(w_roc.shape)\n",
    "        #print('========================================')\n",
    "        auc = roc_auc_score(y_label_roc, y_pred_roc_final, sample_weight=w_roc)\n",
    "        return auc\n",
    "    \n",
    "    if LABELS == 'continuous':\n",
    "        # the original way of calculating auc\n",
    "        y_binary = (y_test > 0.5) * 1.0\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_binary, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_binary, y_proba)\n",
    "        \n",
    "    if LABELS == 'binary1' or LABELS == 'binary2':\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        \n",
    "    plot_roc_curve(fpr, tpr, auc, 'roc_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    \n",
    "    f = open('paper_gen/auc_' + FILENAME_OPTIONS + '.txt', 'a')\n",
    "    f.write(str(config_num) + ',' + str(auc) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(exp_no, epoch_no=50, batch_no=1000):\n",
    "    confs = [1, 2, 3, 4, 5, 6]\n",
    "    for i in range(exp_no):\n",
    "        for conf in confs:\n",
    "            run_config(conf, y, w_a.copy(), w_b.copy(), epoch_no, batch_no)\n",
    "            print('CONFIG', conf, 'DONE')\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print('##########################################################')\n",
    "        print('DONE ITERATION', i)\n",
    "        print('##########################################################')\n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6713 - val_loss: 0.6534\n",
      "Epoch 2/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6526 - val_loss: 0.6514\n",
      "Epoch 3/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6525 - val_loss: 0.6514\n",
      "Epoch 4/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6522 - val_loss: 0.6515\n",
      "Epoch 5/30\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.6520 - val_loss: 0.6513\n",
      "Epoch 6/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6522 - val_loss: 0.6515\n",
      "Epoch 7/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6522 - val_loss: 0.6514\n",
      "Epoch 8/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6523 - val_loss: 0.6513\n",
      "Epoch 9/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6521 - val_loss: 0.6513\n",
      "Epoch 10/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6521 - val_loss: 0.6515\n",
      "Epoch 11/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6524 - val_loss: 0.6543\n",
      "Epoch 12/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6522 - val_loss: 0.6518\n",
      "Epoch 13/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6521 - val_loss: 0.6515\n",
      "Epoch 14/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6521 - val_loss: 0.6513\n",
      "Epoch 15/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6521 - val_loss: 0.6513\n",
      "Epoch 16/30\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.6520 - val_loss: 0.6514\n",
      "Epoch 17/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6520 - val_loss: 0.6513\n",
      "Epoch 18/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6520 - val_loss: 0.6514\n",
      "Epoch 19/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6519 - val_loss: 0.6513\n",
      "Epoch 20/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6519 - val_loss: 0.6514\n",
      "Epoch 21/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6522 - val_loss: 0.6513\n",
      "Epoch 22/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6521 - val_loss: 0.6514\n",
      "Epoch 23/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6520 - val_loss: 0.6513\n",
      "Epoch 24/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6522 - val_loss: 0.6512\n",
      "Epoch 25/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6519 - val_loss: 0.6519\n",
      "Epoch 26/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6520 - val_loss: 0.6513\n",
      "Epoch 27/30\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.6520 - val_loss: 0.6518\n",
      "Epoch 28/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6520 - val_loss: 0.6522\n",
      "Epoch 29/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6520 - val_loss: 0.6515\n",
      "Epoch 30/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6519 - val_loss: 0.6513\n",
      "CONFIG 1 DONE\n",
      "Epoch 1/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6639 - val_loss: 0.6518\n",
      "Epoch 2/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6514 - val_loss: 0.6507\n",
      "Epoch 3/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6500 - val_loss: 0.6493\n",
      "Epoch 4/30\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.6484 - val_loss: 0.6468\n",
      "Epoch 5/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6468 - val_loss: 0.6485\n",
      "Epoch 6/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6453 - val_loss: 0.6452\n",
      "Epoch 7/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6441 - val_loss: 0.6450\n",
      "Epoch 8/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6437 - val_loss: 0.6435\n",
      "Epoch 9/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6431 - val_loss: 0.6421\n",
      "Epoch 10/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6426 - val_loss: 0.6422\n",
      "Epoch 11/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6422 - val_loss: 0.6414\n",
      "Epoch 12/30\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.6421 - val_loss: 0.6415\n",
      "Epoch 13/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6416 - val_loss: 0.6417\n",
      "Epoch 14/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6415 - val_loss: 0.6409\n",
      "Epoch 15/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6412 - val_loss: 0.6413\n",
      "Epoch 16/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6411 - val_loss: 0.6409\n",
      "Epoch 17/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6408 - val_loss: 0.6406\n",
      "Epoch 18/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6408 - val_loss: 0.6407\n",
      "Epoch 19/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6408 - val_loss: 0.6409\n",
      "Epoch 20/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6407 - val_loss: 0.6403\n",
      "Epoch 21/30\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.6406 - val_loss: 0.6413\n",
      "Epoch 22/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6406 - val_loss: 0.6411\n",
      "Epoch 23/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6407 - val_loss: 0.6400\n",
      "Epoch 24/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6404 - val_loss: 0.6404\n",
      "Epoch 25/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6404 - val_loss: 0.6403\n",
      "Epoch 26/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6401 - val_loss: 0.6405\n",
      "Epoch 27/30\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 0.6402 - val_loss: 0.6410\n",
      "Epoch 28/30\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 0.6401 - val_loss: 0.6404\n",
      "Epoch 29/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6401 - val_loss: 0.6400\n",
      "Epoch 30/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6401 - val_loss: 0.6407\n",
      "CONFIG 2 DONE\n",
      "Epoch 1/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.7404 - val_loss: 0.6939\n",
      "Epoch 2/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6943 - val_loss: 0.6952\n",
      "Epoch 3/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6947 - val_loss: 0.6938\n",
      "Epoch 4/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6945 - val_loss: 0.6952\n",
      "Epoch 5/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6943 - val_loss: 0.6937\n",
      "Epoch 6/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6939 - val_loss: 0.6949\n",
      "Epoch 7/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6917 - val_loss: 0.6920\n",
      "Epoch 8/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6897 - val_loss: 0.6907\n",
      "Epoch 9/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6851 - val_loss: 0.6845\n",
      "Epoch 10/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6790 - val_loss: 0.6743\n",
      "Epoch 11/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6627 - val_loss: 0.6556\n",
      "Epoch 12/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6525 - val_loss: 0.6451\n",
      "Epoch 13/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6444 - val_loss: 0.6422\n",
      "Epoch 14/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6415 - val_loss: 0.6403\n",
      "Epoch 15/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6394 - val_loss: 0.6388\n",
      "Epoch 16/30\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 0.6388 - val_loss: 0.6375\n",
      "Epoch 17/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6381 - val_loss: 0.6389\n",
      "Epoch 18/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6371 - val_loss: 0.6368\n",
      "Epoch 19/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6375 - val_loss: 0.6369\n",
      "Epoch 20/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6367 - val_loss: 0.6378\n",
      "Epoch 21/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6364 - val_loss: 0.6357\n",
      "Epoch 22/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6360 - val_loss: 0.6355\n",
      "Epoch 23/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6351 - val_loss: 0.6351\n",
      "Epoch 24/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6357 - val_loss: 0.6362\n",
      "Epoch 25/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6353 - val_loss: 0.6367\n",
      "Epoch 26/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6345 - val_loss: 0.6357\n",
      "Epoch 27/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6347 - val_loss: 0.6354\n",
      "Epoch 28/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6351 - val_loss: 0.6364\n",
      "Epoch 29/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6346 - val_loss: 0.6351\n",
      "Epoch 30/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6346 - val_loss: 0.6388\n",
      "CONFIG 3 DONE\n",
      "Epoch 1/30\n",
      "121/121 [==============================] - 4s 29ms/step - loss: 0.7352 - val_loss: 0.6930\n",
      "Epoch 2/30\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 0.6911 - val_loss: 0.6872\n",
      "Epoch 3/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6765 - val_loss: 0.6704\n",
      "Epoch 4/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6594 - val_loss: 0.6566\n",
      "Epoch 5/30\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 0.6558 - val_loss: 0.6531\n",
      "Epoch 6/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6546 - val_loss: 0.6506\n",
      "Epoch 7/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6530 - val_loss: 0.6521\n",
      "Epoch 8/30\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 0.6518 - val_loss: 0.6509\n",
      "Epoch 9/30\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 0.6515 - val_loss: 0.6496\n",
      "Epoch 10/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6503 - val_loss: 0.6482\n",
      "Epoch 11/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6485 - val_loss: 0.6477\n",
      "Epoch 12/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6470 - val_loss: 0.6471\n",
      "Epoch 13/30\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 0.6469 - val_loss: 0.6456\n",
      "Epoch 14/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6453 - val_loss: 0.6569\n",
      "Epoch 15/30\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.6445 - val_loss: 0.6448\n",
      "Epoch 16/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6436 - val_loss: 0.6420\n",
      "Epoch 17/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6430 - val_loss: 0.6419\n",
      "Epoch 18/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6424 - val_loss: 0.6405\n",
      "Epoch 19/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6419 - val_loss: 0.6424\n",
      "Epoch 20/30\n",
      "121/121 [==============================] - 3s 28ms/step - loss: 0.6414 - val_loss: 0.6420\n",
      "Epoch 21/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6408 - val_loss: 0.6439\n",
      "Epoch 22/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6407 - val_loss: 0.6406\n",
      "Epoch 23/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6403 - val_loss: 0.6406\n",
      "Epoch 24/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6399 - val_loss: 0.6395\n",
      "Epoch 25/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6395 - val_loss: 0.6405\n",
      "Epoch 26/30\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 0.6394 - val_loss: 0.6410\n",
      "Epoch 27/30\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 0.6393 - val_loss: 0.6384\n",
      "Epoch 28/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6390 - val_loss: 0.6390\n",
      "Epoch 29/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6391 - val_loss: 0.6412\n",
      "Epoch 30/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6391 - val_loss: 0.6390\n",
      "CONFIG 4 DONE\n",
      "Epoch 1/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6622 - val_loss: 0.6519\n",
      "Epoch 2/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6509 - val_loss: 0.6494\n",
      "Epoch 3/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6491 - val_loss: 0.6486\n",
      "Epoch 4/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6471 - val_loss: 0.6463\n",
      "Epoch 5/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6449 - val_loss: 0.6440\n",
      "Epoch 6/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6436 - val_loss: 0.6423\n",
      "Epoch 7/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6425 - val_loss: 0.6417\n",
      "Epoch 8/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6417 - val_loss: 0.6416\n",
      "Epoch 9/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6412 - val_loss: 0.6413\n",
      "Epoch 10/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6407 - val_loss: 0.6402\n",
      "Epoch 11/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6404 - val_loss: 0.6398\n",
      "Epoch 12/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6400 - val_loss: 0.6409\n",
      "Epoch 13/30\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.6400 - val_loss: 0.6408\n",
      "Epoch 14/30\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.6396 - val_loss: 0.6394\n",
      "Epoch 15/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6391 - val_loss: 0.6400\n",
      "Epoch 16/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6389 - val_loss: 0.6383\n",
      "Epoch 17/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6388 - val_loss: 0.6391\n",
      "Epoch 18/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6383 - val_loss: 0.6385\n",
      "Epoch 19/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6383 - val_loss: 0.6387\n",
      "Epoch 20/30\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.6382 - val_loss: 0.6382\n",
      "Epoch 21/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6378 - val_loss: 0.6387\n",
      "Epoch 22/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6379 - val_loss: 0.6374\n",
      "Epoch 23/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6379 - val_loss: 0.6378\n",
      "Epoch 24/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6377 - val_loss: 0.6385\n",
      "Epoch 25/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6375 - val_loss: 0.6384\n",
      "Epoch 26/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6376 - val_loss: 0.6379\n",
      "Epoch 27/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6377 - val_loss: 0.6373\n",
      "Epoch 28/30\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.6371 - val_loss: 0.6376\n",
      "Epoch 29/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6372 - val_loss: 0.6373\n",
      "Epoch 30/30\n",
      "121/121 [==============================] - 2s 21ms/step - loss: 0.6370 - val_loss: 0.6369\n",
      "CONFIG 5 DONE\n",
      "Epoch 1/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.7179 - val_loss: 0.6876\n",
      "Epoch 2/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6694 - val_loss: 0.6590\n",
      "Epoch 3/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6584 - val_loss: 0.6578\n",
      "Epoch 4/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6555 - val_loss: 0.6536\n",
      "Epoch 5/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6546 - val_loss: 0.6521\n",
      "Epoch 6/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6523 - val_loss: 0.6522\n",
      "Epoch 7/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6515 - val_loss: 0.6495\n",
      "Epoch 8/30\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6494 - val_loss: 0.6470\n",
      "Epoch 9/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6474 - val_loss: 0.6462\n",
      "Epoch 10/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6469 - val_loss: 0.6440\n",
      "Epoch 11/30\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6451 - val_loss: 0.6459\n",
      "Epoch 12/30\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.6444 - val_loss: 0.6440\n",
      "Epoch 13/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6440 - val_loss: 0.6433\n",
      "Epoch 14/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6421 - val_loss: 0.6437\n",
      "Epoch 15/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6416 - val_loss: 0.6416\n",
      "Epoch 16/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6407 - val_loss: 0.6408\n",
      "Epoch 17/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6407 - val_loss: 0.6394\n",
      "Epoch 18/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6395 - val_loss: 0.6395\n",
      "Epoch 19/30\n",
      "121/121 [==============================] - 2s 21ms/step - loss: 0.6390 - val_loss: 0.6401\n",
      "Epoch 20/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6387 - val_loss: 0.6425\n",
      "Epoch 21/30\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 0.6384 - val_loss: 0.6388\n",
      "Epoch 22/30\n",
      "121/121 [==============================] - 2s 20ms/step - loss: 0.6380 - val_loss: 0.6374\n",
      "Epoch 23/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6382 - val_loss: 0.6375\n",
      "Epoch 24/30\n",
      "121/121 [==============================] - 2s 21ms/step - loss: 0.6377 - val_loss: 0.6414\n",
      "Epoch 25/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6376 - val_loss: 0.6394\n",
      "Epoch 26/30\n",
      "121/121 [==============================] - 3s 21ms/step - loss: 0.6376 - val_loss: 0.6364\n",
      "Epoch 27/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6372 - val_loss: 0.6375\n",
      "Epoch 28/30\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.6368 - val_loss: 0.6374\n",
      "Epoch 29/30\n",
      "121/121 [==============================] - 3s 22ms/step - loss: 0.6371 - val_loss: 0.6370\n",
      "Epoch 30/30\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.6366 - val_loss: 0.6376\n",
      "CONFIG 6 DONE\n",
      "\n",
      "\n",
      "\n",
      "##########################################################\n",
      "DONE ITERATION 0\n",
      "##########################################################\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run 8 experiments\n",
    "#run_experiments(8)\n",
    "\n",
    "run_experiments(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
