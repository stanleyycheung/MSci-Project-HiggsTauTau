{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating https://arxiv.org/pdf/1608.02609.pdf first for $\\rho$-$\\rho$ decays\n",
    "\n",
    "## Inputs:\n",
    "- Invariant masses of intermediate resonances  \n",
    "- Acoplanarity angles\n",
    "- Variables $y_i^+$ ($y_k^-$)\n",
    "- 4 momentum of visible decay products\n",
    "- 4 momentum of intermediate resonances\n",
    "    - If cascade decays, need to provide 4-momenta of all $\\pi^+\\pi^-$ pairs which can form the resonances\n",
    "- Need to boost all four vectors where primary resonances are aligned along the z-axis.\n",
    "- Normalise all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n"
     ]
    }
   ],
   "source": [
    "import uproot \n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Position4\n",
    "from lbn_modified import LBN, LBNLayer\n",
    "from ROOT import TLorentzVector, TVector3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important options\n",
    "\n",
    "# Which channel would you like to use?\n",
    "CHANNEL = 'rho_rho'\n",
    "#CHANNEL = 'rho_a1'\n",
    "#CHANNEL = 'a1_a1'\n",
    "# WARNING: IF YOU CHANGE CHANNEL, YOU HAVE TO RERUN THE WHOLE CODE FROM THE CHANNEL READ-IN!\n",
    "\n",
    "# Which kind of labels do you want to use?\n",
    "#LABELS = 'continuous'\n",
    "LABELS = 'binary1'\n",
    "#LABELS = 'binary2'\n",
    "#WARNING: IF YOU CHANGE LABELS, YOU HAVE TO RERUN THE CREATE LABELS PART!\n",
    "\n",
    "# Which kind of AUC would you like to use?\n",
    "AUC = 'unweighted'\n",
    "#AUC = 'weighted'\n",
    "#WHEN YOU CHANGE AUC, YOU DON'T HAVE TO RERUN ANYTHING!\n",
    "\n",
    "# The output filenames\n",
    "FILENAME_OPTIONS = CHANNEL + '_' + LABELS + '_' + AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_tt = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_GEN_AllHiggs_tt.root\")[\"ntuple\"]\n",
    "\n",
    "# with these variables, the kernel dies\n",
    "variables = [\n",
    "            \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\",\n",
    "            \"dm_1\", \"dm_2\",\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", # charged pion 1\n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", # charged pion 2\n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\", # neutral pion 1\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", # neutral pion 2\n",
    "            ]\n",
    "\n",
    "# with these variables the code runs, but then we don't have selectors...\n",
    "only_4vectors = [\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", # charged pion 1\n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", # charged pion 2\n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\", # neutral pion 1\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", # neutral pion 2\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line takes a long time!\n",
    "df = tree_tt.pandas.df(variables) # this runs for some time until the kernel dies\n",
    "#df = tree_tt.pandas.df(only_4vectors) # this runs but then we don't have selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHANNEL == 'rho_rho':\n",
    "    # select only rho-rho events\n",
    "    df_filtered = df[(df['dm_1']==1) & (df['dm_2']==1)]\n",
    "\n",
    "elif CHANNEL == 'rho_a1':\n",
    "    # select only rho-a1 events\n",
    "    df_filtered = df[(df['dm_1']==1) & (df['dm_2']==10)]\n",
    "\n",
    "elif CHANNEL == 'a1_a1':\n",
    "    # select only a1-a1 events\n",
    "    df_filtered = df[(df['dm_1']==10) & (df['dm_2']==10)]\n",
    "    \n",
    "else:\n",
    "    print('CHANNEL not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels y\n",
    "\n",
    "# necessary for binary2 only:\n",
    "df_filtered_ps = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2)]\n",
    "df_filtered_sm = df_filtered[(df_filtered[\"rand\"]<df_filtered[\"wt_cp_sm\"]/2)]\n",
    "\n",
    "if LABELS == 'continuous':\n",
    "    # non-binary\n",
    "    y = df_filtered[\"wt_cp_sm\"] / (df_filtered[\"wt_cp_ps\"] + df_filtered[\"wt_cp_sm\"])\n",
    "\n",
    "elif LABELS == 'binary1':\n",
    "    # binary method 1\n",
    "    y = (~(df_filtered[\"rand\"]<df_filtered[\"wt_cp_ps\"]/2).to_numpy()).astype(int)\n",
    "\n",
    "elif LABELS == 'binary2':\n",
    "    # binary method 2\n",
    "    y_sm = pd.DataFrame(np.ones(df_filtered_sm.shape[0]))\n",
    "    y_ps = pd.DataFrame(np.zeros(df_filtered_ps.shape[0]))\n",
    "    y = pd.concat([y_sm, y_ps]).to_numpy()\n",
    "\n",
    "else:\n",
    "    print('LABELS not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = df_filtered[\"wt_cp_sm\"].to_numpy()\n",
    "w_b = df_filtered[\"wt_cp_ps\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The particle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse particle information\n",
    "#columns = ['E', 'px', 'py', 'pz']\n",
    "\n",
    "pi_1 = df_filtered[['pi_E_1', \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\"]].to_numpy()\n",
    "pi_2 = df_filtered[['pi_E_2', \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\"]].to_numpy()\n",
    "pi0_1 = df_filtered[['pi0_E_1', \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\"]].to_numpy()\n",
    "pi0_2 = df_filtered[['pi0_E_2', \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct resonance 4 momentum\n",
    "rho_1 = pi_1 + pi0_1\n",
    "rho_2 = pi_2 + pi0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate invariant masses\n",
    "rho_1_m2 = rho_1[:, 0]**2 - rho_1[:, 1]**2 - rho_1[:, 2]**2 - rho_1[:, 3]**2\n",
    "rho_2_m2 = rho_2[:, 0]**2 - rho_2[:, 1]**2 - rho_2[:, 2]**2 - rho_2[:, 3]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = Momentum4(pi_1[:, 0], pi_1[:, 1], pi_1[:, 2], pi_1[:, 3]) # p3 = charged pion 1\n",
    "p4 = Momentum4(pi_2[:, 0], pi_2[:, 1], pi_2[:, 2], pi_2[:, 3]) # p4 = charged pion 2\n",
    "p1 = Momentum4(pi0_1[:, 0], pi0_1[:, 1], pi0_1[:, 2], pi0_1[:, 3]) # p1 = neutral pion 1\n",
    "p2 = Momentum4(pi0_2[:, 0], pi0_2[:, 1], pi0_2[:, 2], pi0_2[:, 3]) # p2 = neutral pion 2\n",
    "rest_frame = p1 + p2 + p3 + p4\n",
    "boost = [rest_frame[0], -rest_frame[1], -rest_frame[2], -rest_frame[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_boosted = p1.boost_particle(boost)\n",
    "p3_boosted = p3.boost_particle(boost)\n",
    "p2_boosted = p2.boost_particle(boost)\n",
    "p4_boosted = p4.boost_particle(boost)\n",
    "\n",
    "r1_boosted = p1_boosted + p3_boosted\n",
    "r2_boosted = p2_boosted + p4_boosted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the high-level variables\n",
    "\n",
    " - aco_angle_1\n",
    " - y_1_1, y_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_1_1 = (charged pion 1 energy - neutral pion 1 energy) / (charged pion 1 energy + neutral pion 1 energy)\n",
    "# y_1_2 calculated in a similar way replacing 1 with 2\n",
    "y_1_1 = (p3_boosted[0] - p1_boosted[0])/(p3_boosted[0] + p1_boosted[0])\n",
    "y_1_2 = (p4_boosted[0] - p2_boosted[0])/(p4_boosted[0] + p2_boosted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aco(p1_boosted, p2_boosted, p3_boosted, p4_boosted):\n",
    "    \"\"\"\n",
    "    The input 4-vectors should be:\n",
    "    Momentum4 instances with shape 4 by ?\n",
    "    The energy (first) row doesn't matter, can be anything\n",
    "    assumes y_1_1 and y_1_2 are known as global variables\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    phi_cps = []\n",
    "    def unit(vect):\n",
    "        return vect / np.linalg.norm(vect)\n",
    "    for pp1, pp2, pp3, pp4 in zip(p1_boosted[:].T, p2_boosted[:].T, p3_boosted[:].T, p4_boosted[:].T):\n",
    "        n1 = pp1[1:] - np.dot(pp1[1:], unit(pp3[1:])) * unit(pp3[1:])\n",
    "        n2 = pp2[1:] - np.dot(pp2[1:], unit(pp4[1:])) * unit(pp4[1:])\n",
    "        n1 = unit(n1)\n",
    "        n2 = unit(n2)\n",
    "\n",
    "        angle = np.arccos(np.dot(n1, n2))\n",
    "        sign = np.dot(unit(pp4[1:]), np.cross(n1, n2))\n",
    "\n",
    "        # shift 1\n",
    "        if sign < 0:\n",
    "            angle = 2 * np.pi - angle\n",
    "\n",
    "        phi_cps.append(angle)\n",
    "        if i%100000==0:\n",
    "            print('finished instance', i)\n",
    "        i += 1\n",
    "        \n",
    "        # this part should be commented out\n",
    "        if y_1_1[i] * y_1_2[i] < 0:\n",
    "            if angle < np.pi:\n",
    "                angle += np.pi\n",
    "            else:\n",
    "                angle -= np.pi\n",
    "        \n",
    "    return phi_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished instance 0\n",
      "finished instance 100000\n",
      "finished instance 200000\n",
      "finished instance 300000\n",
      "finished instance 400000\n",
      "finished instance 500000\n",
      "finished instance 600000\n"
     ]
    }
   ],
   "source": [
    "# calculate aco_angle_1\n",
    "aco_angle_1 = calc_aco(p1_boosted, p2_boosted, p3_boosted, p4_boosted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a52f3bf6fffb>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  unit1 = (r1_boosted[1:, :] / np.linalg.norm(r1_boosted[1:, :], axis=0)).transpose()\n",
      "<ipython-input-13-a52f3bf6fffb>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  unit2 = (r2_boosted[1:, :] / np.linalg.norm(r2_boosted[1:, :], axis=0)).transpose()\n"
     ]
    }
   ],
   "source": [
    "# unit vectors along the momenta of the primary resonances\n",
    "unit1 = (r1_boosted[1:, :] / np.linalg.norm(r1_boosted[1:, :], axis=0)).transpose()\n",
    "unit2 = (r2_boosted[1:, :] / np.linalg.norm(r2_boosted[1:, :], axis=0)).transpose()\n",
    "\n",
    "# probably there's a faster way of doing this\n",
    "zaxis = np.array([np.array([0., 0., 1.]) for _ in range(len(unit1))])\n",
    "\n",
    "axes1 = np.cross(unit1, zaxis)\n",
    "axes2 = np.cross(unit2, zaxis)\n",
    "\n",
    "dotproduct1 = (unit1*zaxis).sum(1)\n",
    "angles1 = np.arccos(dotproduct1)\n",
    "dotproduct2 = (unit2*zaxis).sum(1)\n",
    "angles2 = np.arccos(dotproduct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rotated test_vector is:\n",
      "[ 2.22044605e-16  0.00000000e+00 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / np.dot(axis, axis)**0.5\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def rotate(vect, axis, theta):\n",
    "    return np.dot(rotation_matrix(axis, theta), vect)\n",
    "\n",
    "test_vector = [1, 0, 0]\n",
    "test_axis = [0, 1, 0]\n",
    "test_angle = np.pi/2\n",
    "\n",
    "print('The rotated test_vector is:')\n",
    "print(rotate(test_vector, test_axis, test_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished rotating 3-vector 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-c5ddbe905209>:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  axis = axis / np.dot(axis, axis)**0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished rotating 3-vector 100000\n",
      "finished rotating 3-vector 200000\n",
      "finished rotating 3-vector 300000\n"
     ]
    }
   ],
   "source": [
    "# it would be nice to be able to do the rotation in a vectorized form, like this:\n",
    "#p1rot = rotate(p1_boosted[1:, :].transpose(), axes1, angles1)\n",
    "\n",
    "p1rot = []\n",
    "p2rot = []\n",
    "p3rot = []\n",
    "p4rot = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1rot.append(rotate(p1_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p2rot.append(rotate(p2_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p3rot.append(rotate(p3_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    p4rot.append(rotate(p4_boosted[1:, i], axes1[i], angles1[i]))\n",
    "    if i%100000==0:\n",
    "        print('finished rotating 3-vector', i)\n",
    "p1rot = np.array(p1rot)\n",
    "p2rot = np.array(p2rot)\n",
    "p3rot = np.array(p3rot)\n",
    "p4rot = np.array(p4rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished getting rotated 4-vector 0\n",
      "finished getting rotated 4-vector 100000\n",
      "finished getting rotated 4-vector 200000\n",
      "finished getting rotated 4-vector 300000\n"
     ]
    }
   ],
   "source": [
    "# this should be vectorized as well\n",
    "p1_rotated = []\n",
    "p2_rotated = []\n",
    "p3_rotated = []\n",
    "p4_rotated = []\n",
    "for i in range(p1_boosted[:].shape[1]):\n",
    "    p1_rotated.append([p1_boosted[0, i], p1rot[i, 0], p1rot[i, 1], p1rot[i, 2]])\n",
    "    p2_rotated.append([p2_boosted[0, i], p2rot[i, 0], p2rot[i, 1], p2rot[i, 2]])\n",
    "    p3_rotated.append([p3_boosted[0, i], p3rot[i, 0], p3rot[i, 1], p3rot[i, 2]])\n",
    "    p4_rotated.append([p4_boosted[0, i], p4rot[i, 0], p4rot[i, 1], p4rot[i, 2]])\n",
    "    if i%100000==0:\n",
    "        print('finished getting rotated 4-vector', i)\n",
    "p1_rotated = np.array(p1_rotated).transpose()\n",
    "p2_rotated = np.array(p2_rotated).transpose()\n",
    "p3_rotated = np.array(p3_rotated).transpose()\n",
    "p4_rotated = np.array(p4_rotated).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and labels\n",
    "\n",
    "# this will use the unrotated, boosted 4-vectors:\n",
    "E1 = p1_boosted[0]\n",
    "px1 = p1_boosted[1]\n",
    "py1 = p1_boosted[2]\n",
    "pz1 = p1_boosted[3]\n",
    "E2 = p2_boosted[0]\n",
    "px2 = p2_boosted[1]\n",
    "py2 = p2_boosted[2]\n",
    "pz2 = p2_boosted[3]\n",
    "E3 = p3_boosted[0]\n",
    "px3 = p3_boosted[1]\n",
    "py3 = p3_boosted[2]\n",
    "pz3 = p3_boosted[3]\n",
    "E4 = p4_boosted[0]\n",
    "px4 = p4_boosted[1]\n",
    "py4 = p4_boosted[2]\n",
    "pz4 = p4_boosted[3]\n",
    "\n",
    "# this will use the rotated, boosted 4-vectors:\n",
    "E1r = p1_rotated[0]\n",
    "px1r = p1_rotated[1]\n",
    "py1r = p1_rotated[2]\n",
    "pz1r = p1_rotated[3]\n",
    "E2r = p2_rotated[0]\n",
    "px2r = p2_rotated[1]\n",
    "py2r = p2_rotated[2]\n",
    "pz2r = p2_rotated[3]\n",
    "E3r = p3_rotated[0]\n",
    "px3r = p3_rotated[1]\n",
    "py3r = p3_rotated[2]\n",
    "pz3r = p3_rotated[3]\n",
    "E4r = p4_rotated[0]\n",
    "px4r = p4_rotated[1]\n",
    "py4r = p4_rotated[2]\n",
    "pz4r = p4_rotated[3]\n",
    "\n",
    "# y is defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_aco_angles_added = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nans(X, y, w_a, w_b, config_num=-1):\n",
    "    # this would remove the nans from the feature and the label set\n",
    "    nan_mask = np.array([x.any() for x in np.isnan(X)])\n",
    "    nan_mask_y = np.array([x.any() for x in nan_mask])\n",
    "    #print((nan_mask_y == nan_mask).all())\n",
    "    #print(nan_mask_y.shape)\n",
    "    #print(y.shape)\n",
    "    #print(X.shape)\n",
    "              \n",
    "    new_shape = 21\n",
    "    if config_num == 1:\n",
    "        new_shape = 1\n",
    "    if config_num == 2:\n",
    "        new_shape = 3\n",
    "    if config_num == 3:\n",
    "        new_shape = 16\n",
    "    if config_num == 4:\n",
    "        new_shape = 17\n",
    "    if config_num == 5:\n",
    "        new_shape = 5\n",
    "    if config_num == 6:\n",
    "        new_shape = 21\n",
    "        \n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if config_num == 1:\n",
    "            new_shape = 4\n",
    "        if config_num == 2:\n",
    "            new_shape = 6\n",
    "        if config_num == 3:\n",
    "            new_shape = 16\n",
    "        if config_num == 4:\n",
    "            new_shape = 20\n",
    "        if config_num == 5:\n",
    "            new_shape = 8\n",
    "        if config_num == 6:\n",
    "            new_shape = 24\n",
    "                \n",
    "    X = X[~nan_mask].reshape((-1, new_shape))\n",
    "    y = y[~nan_mask_y]\n",
    "    w_a = w_a[~nan_mask_y]\n",
    "    w_b = w_b[~nan_mask_y]\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    return X, y, w_a, w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple NN\n",
    "def baseline_model2(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(38, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model\n",
    "\n",
    "def baseline_model(dimensions=-1):\n",
    "    if dimensions == -1:\n",
    "        dimensions = X.shape[1]\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(300, input_dim=dimensions, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define a function to plot the ROC curves - just makes the roc_curve look nicer than the default\n",
    "def plot_roc_curve(fpr, tpr, auc, filename='roc_untitled'):\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax.grid()\n",
    "    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n",
    "            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n",
    "    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "    ax.plot(lims, lims, 'k--')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.savefig('paper_gen/' + filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(i):\n",
    "    if i==1:\n",
    "        X = np.reshape(aco_angle_1, (-1, 1))\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==2:\n",
    "        X = np.stack([aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "        #print('SHAPE:')\n",
    "        #print(X.shape)\n",
    "    if i==3:\n",
    "        X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==4:\n",
    "        X = np.stack([aco_angle_1, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "    if i==5:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "    if i==6:\n",
    "        X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, y_1_1, y_1_2], axis=1)\n",
    "\n",
    "    if CHANNEL == 'rho_a1' and other_aco_angles_added:\n",
    "        if i==1:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7], axis=1)\n",
    "        if i==2:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==3:\n",
    "            X = np.stack([E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==4:\n",
    "            X = np.stack([aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r], axis=1)\n",
    "        if i==5:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        if i==6:\n",
    "            X = np.stack([rho_1_m2, rho_2_m2, E1r, px1r, py1r, pz1r, E2r, px2r, py2r, pz2r, E3r, px3r, py3r, pz3r, E4r, px4r, py4r, pz4r, aco_angle_1, aco_angle_5, aco_angle_6, aco_angle_7, y_1_1, y_1_2], axis=1)\n",
    "        \n",
    "        \n",
    "    return X\n",
    "\n",
    "def run_config(config_num, y, w_a, w_b, epoch_number, batch_number):\n",
    "    X = load_config(config_num)\n",
    "\n",
    "    want_filter_nans = False\n",
    "    if CHANNEL == 'rho_a1' or CHANNEL == 'a1_a1':\n",
    "        want_filter_nans = True\n",
    "    if want_filter_nans:\n",
    "        X, y, w_a, w_b = filter_nans(X, y, w_a, w_b, config_num)\n",
    "        \n",
    "    w_a_train, w_a_test, w_b_train, w_b_test  = train_test_split(w_a, w_b, test_size=0.2, random_state=123456)\n",
    "    \n",
    "    # split X and y into train and validation dataset \n",
    "\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=123456,\n",
    "        #stratify=y.values,\n",
    "    )\n",
    "    \n",
    "    # define early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # first run the training for simple case with just 1 variable\n",
    "    history = tf.keras.callbacks.History()\n",
    "\n",
    "    model = baseline_model(X.shape[1])\n",
    "\n",
    "    model.fit(\n",
    "                    X_train, y_train,\n",
    "                    batch_size=batch_number,\n",
    "                    epochs=epoch_number,\n",
    "                    callbacks=[history,early_stop],\n",
    "                    validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Extract number of run epochs from the training history\n",
    "    epochs = range(1, len(history.history[\"loss\"])+1)\n",
    "\n",
    "    # Extract loss on training and validation ddataset and plot them together\n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs, history.history[\"loss\"], \"o-\", label=\"Training\")\n",
    "    plt.plot(epochs, history.history[\"val_loss\"], \"o-\", label=\"Test\")\n",
    "    plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.savefig('paper_gen/history_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    plt.close()\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    # plot ROC curve for improved training\n",
    "    y_proba = model.predict_proba(X_test) # outputs two probabilties\n",
    "    \n",
    "    def stanley_auc():\n",
    "        #Stanley's way of calculating auc\n",
    "        y_pred_roc = model.predict(X_test) #for test dataset\n",
    "        #y_pred_roc = model.predict(X) # for full dataset\n",
    "        y_pred_roc_final = np.r_[y_pred_roc, y_pred_roc]\n",
    "        set_a = np.ones(len(y_pred_roc))\n",
    "        set_b = np.zeros(len(y_pred_roc))\n",
    "        y_label_roc = np.r_[set_a, set_b]\n",
    "        w_roc = np.r_[w_a_test, w_b_test] # for test dataset\n",
    "        #w_roc = np.r_[w_a, w_b] # for full dataset\n",
    "        #print('========================================')\n",
    "        #print(y_label_roc.shape)\n",
    "        #print(y_pred_roc_final.shape)\n",
    "        #print(w_roc.shape)\n",
    "        #print('========================================')\n",
    "        auc = roc_auc_score(y_label_roc, y_pred_roc_final, sample_weight=w_roc)\n",
    "        return auc\n",
    "    \n",
    "    if LABELS == 'continuous':\n",
    "        # the original way of calculating auc\n",
    "        y_binary = (y_test > 0.5) * 1.0\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_binary, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_binary, y_proba)\n",
    "        \n",
    "    if LABELS == 'binary1' or LABELS == 'binary2':\n",
    "        if AUC == 'unweighted':\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        if AUC == 'weighted':\n",
    "            auc = stanley_auc()\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        \n",
    "    plot_roc_curve(fpr, tpr, auc, 'roc_' + FILENAME_OPTIONS + '_config' + str(config_num))\n",
    "    \n",
    "    f = open('paper_gen/auc_' + FILENAME_OPTIONS + '.txt', 'a')\n",
    "    f.write(str(config_num) + ',' + str(auc) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(exp_no, epoch_no=50, batch_no=1000):\n",
    "    confs = [1, 2, 3, 4, 5, 6]\n",
    "    for i in range(exp_no):\n",
    "        for conf in confs:\n",
    "            run_config(conf, y, w_a.copy(), w_b.copy(), epoch_no, batch_no)\n",
    "            print('CONFIG', conf, 'DONE')\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print('##########################################################')\n",
    "        print('DONE ITERATION', i)\n",
    "        print('##########################################################')\n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 47.2230 - val_loss: 17.1797\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 16.1823 - val_loss: 29.5210\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 10.0541 - val_loss: 3.7355\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 4.9031 - val_loss: 7.1544\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 4.0665 - val_loss: 1.4546\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.0929 - val_loss: 7.4955\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.3881 - val_loss: 0.9464\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.0202 - val_loss: 0.9996\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.0670 - val_loss: 0.9398\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 4s 12ms/step - loss: 0.9983 - val_loss: 0.7250\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.2451 - val_loss: 3.0687\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.0103 - val_loss: 0.7105\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7411 - val_loss: 0.7710\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7991 - val_loss: 0.8061\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.8289 - val_loss: 0.7476\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.8413 - val_loss: 0.9040\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.8511 - val_loss: 0.7575\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7901 - val_loss: 0.7178\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7607 - val_loss: 0.7087\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7860 - val_loss: 0.8317\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7620 - val_loss: 0.7120\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 4s 12ms/step - loss: 0.7460 - val_loss: 0.7602\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7799 - val_loss: 0.7073\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7329 - val_loss: 0.6979\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7573 - val_loss: 0.7112\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7381 - val_loss: 0.7282\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7529 - val_loss: 0.7091\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7116 - val_loss: 0.7046\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 4s 12ms/step - loss: 0.7121 - val_loss: 0.6949\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7087 - val_loss: 0.6932\n",
      "CONFIG 1 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 36.2168 - val_loss: 3.7813\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 24.9799 - val_loss: 11.1730\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 12.2383 - val_loss: 18.7270\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 8.1765 - val_loss: 10.2678\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 3.3924 - val_loss: 1.3539\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.9801 - val_loss: 1.1169\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 2.0742 - val_loss: 3.2065\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 1.6914 - val_loss: 0.7087\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.7760 - val_loss: 0.7201\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8341 - val_loss: 1.0703\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8811 - val_loss: 0.8301\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8492 - val_loss: 0.8335\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8417 - val_loss: 1.0644\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.8581 - val_loss: 0.9240\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 4s 13ms/step - loss: 0.7916 - val_loss: 0.7139\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7919 - val_loss: 0.9805\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.0082 - val_loss: 0.6987\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7236 - val_loss: 0.6938\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7197 - val_loss: 0.7170\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7273 - val_loss: 0.7438\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7244 - val_loss: 0.7071\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7235 - val_loss: 0.6951\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7157 - val_loss: 0.6963\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7048 - val_loss: 0.6961\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7116 - val_loss: 0.6943\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7066 - val_loss: 0.7071\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7019 - val_loss: 0.6934\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6978 - val_loss: 0.6934\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6982 - val_loss: 0.6978\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6954 - val_loss: 0.6974\n",
      "CONFIG 2 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.7054 - val_loss: 0.6959\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6963 - val_loss: 0.6942\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6954 - val_loss: 0.6949\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6942 - val_loss: 0.6991\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6940 - val_loss: 0.6932\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6938 - val_loss: 0.6935\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6937 - val_loss: 0.6936\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 5s 17ms/step - loss: 0.6934 - val_loss: 0.6934\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 4s 14ms/step - loss: 0.6933 - val_loss: 0.6933\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6933 - val_loss: 0.6932\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6932 - val_loss: 0.6933\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6932 - val_loss: 0.6932\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6931 - val_loss: 0.6929\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6929 - val_loss: 0.6926\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6926 - val_loss: 0.6923\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6922 - val_loss: 0.6920\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6920 - val_loss: 0.6923\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6920 - val_loss: 0.6914\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6918 - val_loss: 0.6921\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 7s 21ms/step - loss: 0.6916 - val_loss: 0.6917\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.6914 - val_loss: 0.6910\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.6914 - val_loss: 0.6913\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6912 - val_loss: 0.6908\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6912 - val_loss: 0.6912\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6910 - val_loss: 0.6907\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6909 - val_loss: 0.6906\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.6909 - val_loss: 0.6909\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6908 - val_loss: 0.6910\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6908 - val_loss: 0.6904\n",
      "CONFIG 3 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 7s 25ms/step - loss: 50.0436 - val_loss: 3.0774\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 7s 23ms/step - loss: 17.4526 - val_loss: 23.1263\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 11.2540 - val_loss: 9.0480\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 7.2878 - val_loss: 0.8994\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 5s 16ms/step - loss: 3.7237 - val_loss: 4.8235\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 6.1177 - val_loss: 6.3369\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 1.5387 - val_loss: 0.7483\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 7s 24ms/step - loss: 1.2064 - val_loss: 2.2927\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 1.2439 - val_loss: 0.7861\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.8492 - val_loss: 0.9494\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.8890 - val_loss: 0.8780\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.9212 - val_loss: 0.7242\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.7990 - val_loss: 1.3616\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.1313 - val_loss: 0.7092\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7196 - val_loss: 0.8007\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7337 - val_loss: 0.7277\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7447 - val_loss: 0.7369\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7272 - val_loss: 0.7324\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7799 - val_loss: 0.8354\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7741 - val_loss: 0.7063\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7616 - val_loss: 0.6982\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7485 - val_loss: 0.7345\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7716 - val_loss: 0.7050\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7341 - val_loss: 0.7112\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 18ms/step - loss: 0.7348 - val_loss: 0.7012\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7310 - val_loss: 0.6958\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7156 - val_loss: 0.6966\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7137 - val_loss: 0.7759\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7153 - val_loss: 0.6984\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7149 - val_loss: 0.7947\n",
      "CONFIG 4 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 37.4921 - val_loss: 26.5341\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 21.2985 - val_loss: 13.6436\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 9.4956 - val_loss: 10.6581\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 7.1176 - val_loss: 7.5066\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 3.1405 - val_loss: 0.7237\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.5137 - val_loss: 2.2157\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 2.4591 - val_loss: 9.9824\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.7835 - val_loss: 0.7370\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.4670 - val_loss: 1.2239\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.9529 - val_loss: 0.8133\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 18ms/step - loss: 0.9284 - val_loss: 0.6963\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.0745 - val_loss: 0.7010\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8674 - val_loss: 0.7276\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8694 - val_loss: 0.8942\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8402 - val_loss: 0.7868\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8548 - val_loss: 0.9596\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7929 - val_loss: 0.8463\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8023 - val_loss: 0.6934\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8066 - val_loss: 0.7324\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7787 - val_loss: 0.8261\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7603 - val_loss: 0.8174\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7977 - val_loss: 0.8218\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 5s 18ms/step - loss: 0.7445 - val_loss: 0.7062\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7415 - val_loss: 0.6965\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7252 - val_loss: 0.7081\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7173 - val_loss: 0.7675\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7253 - val_loss: 0.6932\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7272 - val_loss: 0.7262\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7143 - val_loss: 0.7094\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.7156 - val_loss: 0.6932\n",
      "CONFIG 5 DONE\n",
      "Epoch 1/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 33.8241 - val_loss: 24.1809\n",
      "Epoch 2/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 23.1632 - val_loss: 8.8852\n",
      "Epoch 3/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 7.5533 - val_loss: 14.1364\n",
      "Epoch 4/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 4.3468 - val_loss: 1.1492\n",
      "Epoch 5/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 5.5151 - val_loss: 2.2354\n",
      "Epoch 6/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 1.1643 - val_loss: 0.8875\n",
      "Epoch 7/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.9815 - val_loss: 0.7237\n",
      "Epoch 8/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 1.0156 - val_loss: 1.7717\n",
      "Epoch 9/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 1.6057 - val_loss: 2.8870\n",
      "Epoch 10/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 1.5301 - val_loss: 0.7179\n",
      "Epoch 11/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7797 - val_loss: 0.8574\n",
      "Epoch 12/30\n",
      "303/303 [==============================] - 6s 19ms/step - loss: 0.8092 - val_loss: 0.8660\n",
      "Epoch 13/30\n",
      "303/303 [==============================] - 5s 18ms/step - loss: 0.8248 - val_loss: 1.2567\n",
      "Epoch 14/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.8159 - val_loss: 1.2272\n",
      "Epoch 15/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.8236 - val_loss: 0.7792\n",
      "Epoch 16/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7660 - val_loss: 0.6965\n",
      "Epoch 17/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7709 - val_loss: 0.6936\n",
      "Epoch 18/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7676 - val_loss: 0.7315\n",
      "Epoch 19/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7510 - val_loss: 0.7616\n",
      "Epoch 20/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7561 - val_loss: 0.6933\n",
      "Epoch 21/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7280 - val_loss: 0.7407\n",
      "Epoch 22/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7415 - val_loss: 0.7010\n",
      "Epoch 23/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7303 - val_loss: 0.7294\n",
      "Epoch 24/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.7128 - val_loss: 0.7148\n",
      "Epoch 25/30\n",
      "303/303 [==============================] - 7s 22ms/step - loss: 0.7109 - val_loss: 0.6984\n",
      "Epoch 26/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7094 - val_loss: 0.6933\n",
      "Epoch 27/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7144 - val_loss: 0.6934\n",
      "Epoch 28/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7140 - val_loss: 0.6932\n",
      "Epoch 29/30\n",
      "303/303 [==============================] - 6s 21ms/step - loss: 0.6990 - val_loss: 0.6995\n",
      "Epoch 30/30\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7010 - val_loss: 0.6935\n",
      "CONFIG 6 DONE\n",
      "\n",
      "\n",
      "\n",
      "##########################################################\n",
      "DONE ITERATION 0\n",
      "##########################################################\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run 8 experiments\n",
    "#run_experiments(8)\n",
    "\n",
    "run_experiments(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
