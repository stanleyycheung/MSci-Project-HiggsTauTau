{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pylorentz --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
    "from pylorentz import Momentum4\n",
    "from pylorentz import Position4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_tt = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_AllHiggs_tt.root\")[\"ntuple\"]\n",
    "tree_tt = uproot.open(\"/eos/user/s/stcheung/SWAN_projects/Masters_CP/MVAFILE_AllHiggs_tt.root\")[\"ntuple\"]\n",
    "print('loaded root file')\n",
    "variables = [\n",
    "            \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\",\n",
    "            \"aco_angle_1\", \"aco_angle_5\", \"aco_angle_6\", \"aco_angle_7\", \n",
    "            \"mva_dm_1\",\"mva_dm_2\",\n",
    "            \"tau_decay_mode_1\",\"tau_decay_mode_2\",\n",
    "            \"ip_x_1\", \"ip_y_1\", \"ip_z_1\", \"ip_x_2\", \"ip_y_2\", \"ip_z_2\", # ignore impact parameter for now\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", \n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", \n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\",\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", \n",
    "            \"y_1_1\", \"y_1_2\",\n",
    "            'met', 'metx', 'mety',\n",
    "            'metCov00', 'metCov01', 'metCov10', 'metCov11'\n",
    "            'sv_x_1', 'sv_y_1', 'sv_z_1', 'sv_x_2', 'sv_y_2','sv_z_2'\n",
    "        ]\n",
    "\n",
    "variables += [\"gen_nu_p_1\", \"gen_nu_phi_1\", \"gen_nu_eta_1\", #leading neutrino, gen level\n",
    "            \"gen_nu_p_2\", \"gen_nu_phi_2\", \"gen_nu_eta_2\" #subleading neutrino, gen level\n",
    "             ]\n",
    "\n",
    "df_tt = tree_tt.pandas.df(variables)\n",
    "print('loaded df')\n",
    "# select only rho-rho events\n",
    "df_rho = df[(df['mva_dm_1']==1) & (df['mva_dm_2']==1) & (df[\"tau_decay_mode_1\"] == 1) & (df[\"tau_decay_mode_2\"] == 1)]\n",
    "# drop unnecessary labels \n",
    "df = df_rho.drop([\"mva_dm_1\",\"mva_dm_2\",\"tau_decay_mode_1\",\"tau_decay_mode_2\", \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\"], axis=1).reset_index(drop=True)\n",
    "print('finished rho-rho loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen level data\n",
    "tree_tt_gen = uproot.open(\"/eos/user/d/dwinterb/SWAN_projects/Masters_CP/MVAFILE_GEN_AllHiggs_tt.root\")[\"ntuple\"]\n",
    "variables_gen = [\n",
    "            \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\",\n",
    "            \"dm_1\", \"dm_2\",\n",
    "            \"pi_E_1\", \"pi_px_1\", \"pi_py_1\", \"pi_pz_1\", # charged pion 1\n",
    "            \"pi_E_2\", \"pi_px_2\", \"pi_py_2\", \"pi_pz_2\", # charged pion 2\n",
    "            \"pi0_E_1\", \"pi0_px_1\", \"pi0_py_1\", \"pi0_pz_1\", # neutral pion 1\n",
    "            \"pi0_E_2\", \"pi0_px_2\", \"pi0_py_2\", \"pi0_pz_2\", # neutral pion 2,\n",
    "            'metx', 'mety',\n",
    "            ]\n",
    "df_tt_gen = tree_tt_gen.pandas.df(variables_gen)\n",
    "df_rho = df_tt_gen[(df_tt_gen['dm_1']==1) & (df_tt_gen['dm_2']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt_gen.to_pickle('./df_tt_gen.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tt_gen = pd.read_pickle('./df_tt_gen.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt.to_pickle('./df_tt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tt = pd.read_pickle('df_tt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'rho_rho'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reco level data\n",
    "if channel == 'rho_rho':\n",
    "    df_rho = df_tt[(df_tt['mva_dm_1']==1) & (df_tt['mva_dm_2']==1) & (df_tt[\"tau_decay_mode_1\"] == 1) & (df_tt[\"tau_decay_mode_2\"] == 1)]\n",
    "    df = df_rho.drop([\"mva_dm_1\",\"mva_dm_2\",\"tau_decay_mode_1\",\"tau_decay_mode_2\", \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\"], axis=1).reset_index(drop=True)\n",
    "elif channel == 'rho_a1':\n",
    "    df_rho_a1 = df_tt[(df_tt['mva_dm_1']==1) & (df_tt['mva_dm_2']==10) & (df_tt[\"tau_decay_mode_1\"] == 1)]\n",
    "    df = df_rho_a1.drop([\"mva_dm_1\",\"mva_dm_2\",\"tau_decay_mode_1\",\"tau_decay_mode_2\", \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\"], axis=1).reset_index(drop=True)\n",
    "elif channel == 'a1_a1':\n",
    "    df_a1_a1 = df_tt[(df_tt['mva_dm_1']==10) & (df_tt['mva_dm_2']==10)]\n",
    "    df = df_a1_a1.drop([\"mva_dm_1\",\"mva_dm_2\",\"tau_decay_mode_1\",\"tau_decay_mode_2\", \"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\"], axis=1).reset_index(drop=True)    \n",
    "else:\n",
    "    print('CHANNEL not understood!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen level data NEED TO CHECK FOR TAU DECAY MODE LABEL\n",
    "if channel == 'rho_rho':\n",
    "    df_rho = df_tt_gen[(df_tt_gen['dm_1']==1) & (df_tt_gen['dm_2']==1)]\n",
    "    df = df_rho.drop([\"dm_1\",\"dm_2\",\"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\"], axis=1).reset_index(drop=True)\n",
    "elif channel == 'rho_a1':\n",
    "    df_rho_a1 = df_tt_gen[(df_tt_gen['dm_1']==1) & (df_tt_gen['dm_2']==10)]\n",
    "    df = df_rho_a1.drop([\"dm_1\",\"dm_2\",\"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\"], axis=1).reset_index(drop=True)\n",
    "elif channel == 'a1_a1':\n",
    "    df_a1_a1 = df_tt_gen[(df_tt_gen['dm_1']==10) & (df_tt_gen['dm_2']==10)]\n",
    "    df = df_a1_a1.drop([\"dm_1\",\"dm_2\",\"wt_cp_sm\", \"wt_cp_ps\", \"wt_cp_mm\", \"rand\"], axis=1).reset_index(drop=True)\n",
    "else:\n",
    "    print('CHANNEL not understood!')\n",
    "df['met'] = np.sqrt(df['metx']**2+df['mety']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = (~(df_rho[\"rand\"]<df_rho[\"wt_cp_ps\"]/2).to_numpy()).astype(int)\n",
    "# np.save('./potential_2016/y_kristof', y, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df['metx'])\n",
    "met_x = Momentum4(df['metx'], np.zeros(N), np.zeros(N), np.zeros(N))\n",
    "met_y = Momentum4(df['mety'], np.zeros(N), np.zeros(N), np.zeros(N))\n",
    "met = Momentum4(df['met'], np.zeros(N), np.zeros(N), np.zeros(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_1 = Momentum4(df['pi_E_1'], df[\"pi_px_1\"], df[\"pi_py_1\"], df[\"pi_pz_1\"])\n",
    "pi_2 = Momentum4(df['pi_E_2'], df[\"pi_px_2\"], df[\"pi_py_2\"], df[\"pi_pz_2\"])\n",
    "pi0_1 = Momentum4(df['pi0_E_1'], df[\"pi0_px_1\"], df[\"pi0_py_1\"], df[\"pi0_pz_1\"])\n",
    "pi0_2 = Momentum4(df['pi0_E_2'], df[\"pi0_px_2\"], df[\"pi0_py_2\"], df[\"pi0_pz_2\"])\n",
    "rho_1 = pi_1 + pi0_1\n",
    "rho_2 = pi_2 + pi0_2\n",
    "# rho_1.m is invariant mass of rhos\n",
    "# boost into rest frame of resonances\n",
    "rest_frame = pi_1 + pi_2 + pi0_1 + pi0_2\n",
    "boost = Momentum4(rest_frame[0], -rest_frame[1], -rest_frame[2], -rest_frame[3])\n",
    "pi_1_boosted = pi_1.boost_particle(boost)\n",
    "pi_2_boosted = pi_2.boost_particle(boost)\n",
    "pi0_1_boosted = pi0_1.boost_particle(boost)\n",
    "pi0_2_boosted = pi0_2.boost_particle(boost)\n",
    "rho_1_boosted = pi_1_boosted + pi0_1_boosted\n",
    "rho_2_boosted = pi_2_boosted + pi0_2_boosted\n",
    "# boost MET\n",
    "met_x_boosted = met_x.boost_particle(boost)\n",
    "met_y_boosted = met_y.boost_particle(boost)\n",
    "met_boosted = met.boost_particle(boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished getting rotated 4-vector 0\n",
      "finished getting rotated 4-vector 100000\n",
      "finished getting rotated 4-vector 200000\n",
      "finished getting rotated 4-vector 300000\n",
      "finished getting rotated 4-vector 400000\n",
      "finished getting rotated 4-vector 500000\n",
      "finished getting rotated 4-vector 600000\n",
      "finished getting rotated 4-vector 700000\n",
      "finished getting rotated 4-vector 800000\n",
      "finished getting rotated 4-vector 900000\n"
     ]
    }
   ],
   "source": [
    "# rotations\n",
    "def rotation_matrix_from_vectors(vec1, vec2):\n",
    "    \"\"\" Find the rotation matrix that aligns vec1 to vec2\n",
    "    :param vec1: A 3d \"source\" vector\n",
    "    :param vec2: A 3d \"destination\" vector\n",
    "    :return mat: A transform matrix (3x3) which when applied to vec1, aligns it with vec2.\n",
    "    \"\"\"\n",
    "    a, b = (vec1 / np.linalg.norm(vec1)).reshape(3), (vec2 / np.linalg.norm(vec2)).reshape(3)\n",
    "    v = np.cross(a, b)\n",
    "    c = np.dot(a, b)\n",
    "    s = np.linalg.norm(v)\n",
    "    kmat = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\n",
    "    rotation_matrix = np.eye(3) + kmat + kmat.dot(kmat) * ((1 - c) / (s ** 2))\n",
    "    return rotation_matrix\n",
    "    \n",
    "pi_1_boosted_rot = []\n",
    "pi_2_boosted_rot = []\n",
    "pi0_1_boosted_rot = []\n",
    "pi0_2_boosted_rot = []\n",
    "rho_1_boosted_rot = []\n",
    "rho_2_boosted_rot = []\n",
    "for i in range(pi_1_boosted[:].shape[1]):\n",
    "    rot_mat = rotation_matrix_from_vectors(rho_1_boosted[1:, i], [0,0,1])\n",
    "    pi_1_boosted_rot.append(rot_mat.dot(pi_1_boosted[1:, i]))\n",
    "    pi0_1_boosted_rot.append(rot_mat.dot(pi0_1_boosted[1:, i]))\n",
    "    pi_2_boosted_rot.append(rot_mat.dot(pi_2_boosted[1:, i]))\n",
    "    pi0_2_boosted_rot.append(rot_mat.dot(pi0_2_boosted[1:, i]))\n",
    "    rho_1_boosted_rot.append(rot_mat.dot(rho_1_boosted[1:, i]))\n",
    "    rho_2_boosted_rot.append(rot_mat.dot(rho_2_boosted[1:, i]))\n",
    "    if i%100000==0:\n",
    "        print('finished getting rotated 4-vector', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('reco_info/rho_rho/pi_1_boosted_rot.npy', pi_1_boosted_rot, allow_pickle=True)\n",
    "np.save('reco_info/rho_rho/pi_2_boosted_rot.npy', pi_2_boosted_rot, allow_pickle=True)\n",
    "np.save('reco_info/rho_rho/pi0_1_boosted_rot.npy', pi0_1_boosted_rot, allow_pickle=True)\n",
    "np.save('reco_info/rho_rho/pi0_2_boosted_rot.npy', pi0_2_boosted_rot, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_miss_boosted = met_boosted[0]\n",
    "E_miss_x_boosted = met_x_boosted[0]\n",
    "E_miss_y_boosted = met_y_boosted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_load = []\n",
    "# to_load_names = [\"pi_1_transformed\", \"pi_2_transformed\", \"pi0_1_transformed\", \"pi0_2_transformed\", \"rho_1_transformed\", \"rho_2_transformed\", \"aco_angle_1\", \"y_1_1\", \"y_1_2\", \"m_1\", \"m_2\", \"w_a\", \"w_b\"]\n",
    "# for i in range(len(to_load_names)):\n",
    "#     to_load.append(np.load(f'potential_2016/{to_load_names[i]}.npy', allow_pickle=True))\n",
    "# pi_1_transformed, pi_2_transformed, pi0_1_transformed, pi0_2_transformed, rho_1_transformed, rho_2_transformed, aco_angle_1, y_1_1, y_1_2, m_1, m_2, w_a, w_b = to_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pi_1_boosted_rot = pi_1_transformed[:, 1:]\n",
    "# pi_2_boosted_rot = pi_2_transformed[:, 1:]\n",
    "# pi0_1_boosted_rot = pi0_1_transformed[:, 1:]\n",
    "# pi0_2_boosted_rot = pi0_2_transformed[:, 1:]\n",
    "# rho_1_boosted_rot = rho_1_transformed[:, 1:]\n",
    "# rho_2_boosted_rot = rho_2_transformed[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs = rho_1_boosted + rho_2_boosted\n",
    "m_tau = 1.776\n",
    "m_rho = 0.7754\n",
    "m_higgs = 125.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_miss = df['met'].to_numpy()\n",
    "E_miss_x = df['metx'].to_numpy()\n",
    "E_miss_y = df['mety'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rho_1_boosted_rot = np.array(rho_1_boosted_rot)\n",
    "rho_2_boosted_rot = np.array(rho_2_boosted_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha(mode):\n",
    "    if mode == 1:\n",
    "        alpha_2 = (E_miss_y*rho_1[1]-E_miss_x*rho_1[2])/(rho_2[2]*rho_1[1]-rho_2[1]*rho_1[2])\n",
    "        alpha_1 = (E_miss_x - alpha_2*rho_2[1])/rho_1[1]\n",
    "    elif mode == 2:\n",
    "        alpha_1 = (E_miss_y*rho_2[1]-E_miss_x*rho_2[2])/(rho_1[2]*rho_2[1]-rho_1[1]*rho_2[2])\n",
    "        alpha_2 = (m_higgs**2/2 - m_tau**2)/(rho_1[0]*rho_2[0]-rho_1[1]*rho_2[1]-rho_1[2]*rho_1[2]-rho_1[3]*rho_1[3])/(1+alpha_1) - 1\n",
    "    elif mode == 3:\n",
    "        alpha_2 = (E_miss_y*rho_1[1]-E_miss_x*rho_1[2])/(rho_2[2]*rho_1[1]-rho_2[1]*rho_1[2])\n",
    "        alpha_1 = (m_higgs**2/2 - m_tau**2)/(rho_1[0]*rho_2[0]-rho_1[1]*rho_2[1]-rho_1[2]*rho_1[2]-rho_1[3]*rho_1[3])/(1+alpha_2) - 1\n",
    "    else:\n",
    "        raise InputError('incorrect mode in parameters')\n",
    "    return alpha_1, alpha_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(var, mode=0):\n",
    "    if mode == 0:\n",
    "        print(f\"Fraction of < 0 in {var}: {(eval(var)<0).sum()/len(eval(var)):.3f}, {(eval(var)>0).sum()} values left\")\n",
    "    elif mode == 1:\n",
    "        print(f'Fraction of NaNs in {var}: {np.isnan(eval(var)).sum()/len(eval(var)):.3f}, {len(eval(var))-np.isnan(eval(var)).sum()} values left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate alphas from gaussian distribution\n",
    "def getAlpha(mode, termination=1000):\n",
    "    alpha_1, alpha_2 = calc_alpha(mode)\n",
    "    if alpha_1 < 0:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of < 0 in alpha_1: 0.459, 540254 values left\n",
      "Fraction of < 0 in alpha_2: 0.435, 563774 values left\n",
      "Fraction of < 0 in E_nu_1: 0.458, 540637 values left\n",
      "Fraction of < 0 in E_nu_2: 0.435, 564082 values left\n",
      "Fraction of NaNs in p_t_nu_1: 0.495, 504333 values left\n",
      "Fraction of NaNs in p_t_nu_2: 0.480, 519486 values left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-e3a375a7aa8f>:15: RuntimeWarning: invalid value encountered in sqrt\n",
      "  p_t_nu_1 = np.sqrt(E_nu_1**2 - p_z_nu_1**2)\n",
      "<ipython-input-15-e3a375a7aa8f>:16: RuntimeWarning: invalid value encountered in sqrt\n",
      "  p_t_nu_2 = np.sqrt(E_nu_2**2 - p_z_nu_2**2)\n"
     ]
    }
   ],
   "source": [
    "# use lab frame calculate alphas\n",
    "alpha_1, alpha_2 = calc_alpha(1)\n",
    "\n",
    "evaluate('alpha_1')\n",
    "evaluate('alpha_2')\n",
    "# # set negative alpha to None\n",
    "# alpha_1[alpha_1<0] = None\n",
    "# alpha_2[alpha_2<0] = None\n",
    "\n",
    "# z component of neutrino mom (use boosted and rot frame now)\n",
    "p_z_nu_1 = alpha_1*rho_1_boosted_rot[:, 2]\n",
    "p_z_nu_2 = alpha_2*rho_2_boosted_rot[:, 2]\n",
    "E_nu_1 = (m_tau**2 - rho_1_boosted[0]**2 + rho_1_boosted_rot[:, 2]**2 + 2*p_z_nu_1*rho_1_boosted_rot[:, 2])/(2*rho_1_boosted[0])\n",
    "E_nu_2 = (m_tau**2 - rho_2_boosted[0]**2 + rho_2_boosted_rot[:, 2]**2 + 2*p_z_nu_2*rho_2_boosted_rot[:, 2])/(2*rho_2_boosted[0])\n",
    "p_t_nu_1 = np.sqrt(E_nu_1**2 - p_z_nu_1**2)\n",
    "p_t_nu_2 = np.sqrt(E_nu_2**2 - p_z_nu_2**2)\n",
    "\n",
    "# need to check alpha and E are positive - seen total 17% of values rej (right now only see from rho-rho decay chain)\n",
    "\n",
    "evaluate('E_nu_1')\n",
    "evaluate('E_nu_2')\n",
    "evaluate('p_t_nu_1', 1)\n",
    "evaluate('p_t_nu_2', 1)\n",
    "\n",
    "# # set negative alphas and E to None values\n",
    "# alpha_1[alpha_1<0] = None\n",
    "# alpha_2[alpha_2<0] = None\n",
    "\n",
    "# make negative p_t values to 0\n",
    "p_t_nu_1[np.isnan(p_t_nu_1)] = 0\n",
    "p_t_nu_2[np.isnan(p_t_nu_2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_a_1 = np.where(alpha_1<0)[0]\n",
    "idx_a_2 = np.where(alpha_2<0)[0]\n",
    "idx_E_1 = np.where(E_nu_1<0)[0]\n",
    "idx_E_2 = np.where(E_nu_2<0)[0]\n",
    "i1 = np.union1d(idx_a_1, idx_E_1)\n",
    "i2 = np.union1d(idx_a_2, idx_E_2)\n",
    "print(f'Events left from tau_1: {alpha_1.shape[0]-i1.shape[0]}')\n",
    "print(f'Events left from tau_2: {alpha_2.shape[0]-i2.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to remove events that are rejected (for now)\n",
    "df['alpha_1'] = alpha_1\n",
    "df['alpha_2'] = alpha_2\n",
    "df['E_nu_1'] = E_nu_1\n",
    "df['E_nu_2'] = E_nu_2\n",
    "df['p_t_nu_1'] = p_t_nu_1\n",
    "df['p_t_nu_2'] = p_t_nu_2\n",
    "df_red = df[(df['alpha_1']>0) & (df['alpha_2']>0) & (df['E_nu_1']>0) & (df['E_nu_2']>0)].reset_index(drop=True)\n",
    "\n",
    "df_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-df_red.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results\n",
    "\n",
    "### for approx 1\n",
    "- rho-rho channel: 0.459/0.453 alpha - 61.6% total rej\n",
    "- rho-a1 channel: 0.461/0.502 alpha - 65.5% total rej\n",
    "- a1-a1 channel: 0.507/0.489 alpha - 68.5% total rej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from paper - doesn't work because SV isn't always defined\n",
    "c = 299792458\n",
    "t_flight = 87e-6/c\n",
    "# calculate in lab frame\n",
    "p_x_tau_1 = -m_tau*df['sv_x_1']/t_flight\n",
    "p_y_tau_1 = -m_tau*df['sv_y_1']/t_flight\n",
    "p_y_tau_1 = -m_tau*df['sv_y_1']/t_flight\n",
    "p_x_tau_2 = -m_tau*df['sv_x_2']/t_flight\n",
    "p_y_tau_2 = -m_tau*df['sv_y_2']/t_flight\n",
    "p_y_tau_2 = -m_tau*df['sv_y_2']/t_flight\n",
    "# need to convert units of p\n",
    "E_tau_1 = np.sqrt(p_x_tau_1**2+p_y_tau_1**2+p_z_tau_1**2+m_tau**2)\n",
    "E_tau_2 = np.sqrt(p_x_tau_2**2+p_y_tau_2**2+p_z_tau_2**2+m_tau**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rho reconstruction check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14, \"figure.figsize\": (10,6)})\n",
    "n_1, bins_1, patches_1 = plt.hist(rho_1.m, bins=2000, label=f\"Peak rho_1 mass: {bins_1[np.where(n_1==n_1.max())][0]:.4f} Gev\")\n",
    "n_2, bins_2, patches_2 = plt.hist(rho_2.m, bins=2000, label=f\"Peak rho_2 mass: {bins_2[np.where(n_2==n_2.max())][0]:.4f} Gev\")\n",
    "\n",
    "plt.xlim([0,5])\n",
    "plt.legend()\n",
    "plt.ylabel('Freq')\n",
    "plt.xlabel('Mass (Gev)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rho_reconstruction.PNG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
